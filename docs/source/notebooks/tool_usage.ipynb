{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# Tool Usage\n",
    "\n",
    "Let's see how to evaluate an agent's ability to use tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03488ab1-31ed-41c2-8da2-46b02599b181",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                            </th><th>Type          </th><th>Dataset ID                                                               </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Tool Usage - Typewriter (1 func)</td><td>ToolUsageTask </td><td>placeholder                                                              </td><td>Environment with a single function that accepts a single letter as input, and &quot;prints&quot; it on a piece of paper.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to repeat a given input string.\n",
       "\n",
       "For example, if the string is &#x27;abc&#x27;, the tools &#x27;a&#x27;, &#x27;b&#x27;, and &#x27;c&#x27; must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.              </td></tr>\n",
       "<tr><td>Tool Usage - Typewriter         </td><td>ToolUsageTask </td><td>placeholder                                                              </td><td>Environment with 26 functions each representing a letter of the alphabet.\n",
       "\n",
       "In this variation of the typewriter task, there are 26 parameterless functions, where each function represents a letter of the alphabet (instead of a single function that takes a letter as an argument).\n",
       "\n",
       "The object is to evaluate the ability of use the functions to repeat the given string.\n",
       "\n",
       "For example, if the string is &#x27;abc&#x27;, the tools &#x27;a&#x27;, &#x27;b&#x27;, and &#x27;c&#x27; must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.              </td></tr>\n",
       "<tr><td>Tool Usage - Relational Data    </td><td>ToolUsageTask </td><td>e95d45da-aaa3-44b3-ba2b-7c15ff6e46f5                                     </td><td>Environment with fake data about users and their locations and favorite foods.\n",
       "\n",
       "The environment provides a set of tools that can be used to query the data.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\n",
       "\n",
       "The dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\n",
       "\n",
       "Each example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\n",
       "\n",
       "Success is measured by the ability to answer the question correctly, and efficiently.              </td></tr>\n",
       "<tr><td>Multiverse Math                 </td><td>ToolUsageTask </td><td>placeholder                                                              </td><td>An environment that contains a few basic math operations, but with altered results.\n",
       "\n",
       "For example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.              </td></tr>\n",
       "<tr><td>Email Extraction                </td><td>ExtractionTask</td><td>https://smith.langchain.com/public/36bdfe7d-3cd1-4b36-b957-d12d95810a2b/d</td><td>A dataset of 42 real emails deduped from a spam folder, with semantic HTML tags removed, as well as a script for initial extraction and formatting of other emails from an arbitrary .mbox file like the one exported by Gmail.\n",
       "\n",
       "Some additional cleanup of the data was done by hand after the initial pass.\n",
       "\n",
       "See https://github.com/jacoblee93/oss-model-extraction-evals.              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[ToolUsageTask(name='Tool Usage - Typewriter (1 func)', dataset_id='placeholder', description='Environment with a single function that accepts a single letter as input, and \"prints\" it on a piece of paper.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to repeat a given input string.\\n\\nFor example, if the string is \\'abc\\', the tools \\'a\\', \\'b\\', and \\'c\\' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n', create_environment=<function get_environment at 0x7f5a11d82a60>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the function with a single letter at a time.\"), ToolUsageTask(name='Tool Usage - Typewriter', dataset_id='placeholder', description=\"Environment with 26 functions each representing a letter of the alphabet.\\n\\nIn this variation of the typewriter task, there are 26 parameterless functions, where each function represents a letter of the alphabet (instead of a single function that takes a letter as an argument).\\n\\nThe object is to evaluate the ability of use the functions to repeat the given string.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\", create_environment=<function get_environment at 0x7f5a11d82670>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\"), ToolUsageTask(name='Tool Usage - Relational Data', dataset_id='e95d45da-aaa3-44b3-ba2b-7c15ff6e46f5', description='Environment with fake data about users and their locations and favorite foods.\\n\\nThe environment provides a set of tools that can be used to query the data.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\\n\\nThe dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\\n\\nEach example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\\n\\nSuccess is measured by the ability to answer the question correctly, and efficiently.\\n', create_environment=<function get_environment at 0x7f5a11d8c0d0>, instructions=\"Please answer the user's question by using the tools provided. Do not guess the answer. Keep in mind that entities like users,foods and locations have both a name and an ID, which are not the same.\"), ToolUsageTask(name='Multiverse Math', dataset_id='placeholder', description='An environment that contains a few basic math operations, but with altered results.\\n\\nFor example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.\\n', create_environment=<function get_environment at 0x7f5a11d8c670>, instructions='You are requested to solve math questions in an alternate mathematical universe. The rules of association, commutativity, and distributivity still apply, but the operations have been altered to yield different results than expected. Solve the given math questions using the provided tools. Do not guess the answer.'), ExtractionTask(name='Email Extraction', dataset_id='https://smith.langchain.com/public/36bdfe7d-3cd1-4b36-b957-d12d95810a2b/d', description='A dataset of 42 real emails deduped from a spam folder, with semantic HTML tags removed, as well as a script for initial extraction and formatting of other emails from an arbitrary .mbox file like the one exported by Gmail.\\n\\nSome additional cleanup of the data was done by hand after the initial pass.\\n\\nSee https://github.com/jacoblee93/oss-model-extraction-evals.\\n    ', model=<class 'langchain_benchmarks.extraction.email_task.Email'>)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f22779-a948-4833-8e8c-ace9ef17f56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Relational Data        </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                       </td></tr>\n",
       "<tr><td>Dataset ID </td><td>e95d45da-aaa3-44b3-ba2b-7c15ff6e46f5</td></tr>\n",
       "<tr><td>Description</td><td>Environment with fake data about users and their locations and favorite foods.\n",
       "\n",
       "The environment prov...                                     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Relational Data', dataset_id='e95d45da-aaa3-44b3-ba2b-7c15ff6e46f5', description='Environment with fake data about users and their locations and favorite foods.\\n\\nThe environment provides a set of tools that can be used to query the data.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\\n\\nThe dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\\n\\nEach example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\\n\\nSuccess is measured by the ability to answer the question correctly, and efficiently.\\n', create_environment=<function get_environment at 0x7f5a11d8c0d0>, instructions=\"Please answer the user's question by using the tools provided. Do not guess the answer. Keep in mind that entities like users,foods and locations have both a name and an ID, which are not the same.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Relational Data\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49be36d2-343e-49df-8369-dd5bac405d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with fake data about users and their locations and favorite foods.\n",
      "\n",
      "The environment provides a set of tools that can be used to query the data.\n",
      "\n",
      "The objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\n",
      "\n",
      "The dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\n",
      "\n",
      "Each example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\n",
      "\n",
      "Success is measured by the ability to answer the question correctly, and efficiently.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33a639-3caf-4314-8ea7-1c7c8b1d114d",
   "metadata": {},
   "source": [
    "Clone the dataset associaetd with this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Tool Usage - Relational Data already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/f2b5a831-8eef-4bc7-b6de-68078b87350f.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(task.dataset_id, dataset_name=task.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462f7b8-fd42-4613-ab5f-5f3cbbc37d28",
   "metadata": {},
   "source": [
    "## Define an agent\n",
    "\n",
    "Let's build an agent that we can use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09469813-17b6-4456-a913-486a01a4b295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks.tool_usage import agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae8c6be-899c-44a6-a89b-0fc04c2cb05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_factory = agents.OpenAIAgentFactory(task, model=\"gpt-3.5-turbo-16k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a64f76-65ae-4367-b43f-f2be3431e7af",
   "metadata": {},
   "source": [
    "Let's test that our agent works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612fb603-1401-426b-8a19-4453ad5b698a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = agent_factory.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4896fa-3633-44a1-857f-80a263cf2e03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who is bob?',\n",
       " 'output': 'Bob is a user with the name \"Bob\".',\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='find_users_by_name', tool_input={'name': 'bob'}, log=\"\\nInvoking: `find_users_by_name` with `{'name': 'bob'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"name\": \"bob\"\\n}', 'name': 'find_users_by_name'}})]),\n",
       "   [{'id': 21, 'name': 'Bob'},\n",
       "    {'id': 41, 'name': 'Donna'},\n",
       "    {'id': 1, 'name': 'Alice'},\n",
       "    {'id': 35, 'name': 'Charlie'},\n",
       "    {'id': 42, 'name': 'Eve'},\n",
       "    {'id': 43, 'name': 'Frank The Cat'}]),\n",
       "  (AgentActionMessageLog(tool='get_user_name', tool_input={'user_id': 21}, log=\"\\nInvoking: `get_user_name` with `{'user_id': 21}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"user_id\": 21\\n}', 'name': 'get_user_name'}})]),\n",
       "   'Bob')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"question\": \"who is bob?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "## Eval\n",
    "\n",
    "Let's evaluate an agent now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513042fe-2878-44f8-ae84-05b9d521c1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks.tool_usage import STANDARD_AGENT_EVALUATOR\n",
    "from langsmith.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bedd9d1-fc06-4066-9f89-b874ae818d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=agent_factory.create,\n",
    "    evaluation=STANDARD_AGENT_EVALUATOR,\n",
    "    verbose=True,\n",
    "    tags=[\"openai-functions\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
