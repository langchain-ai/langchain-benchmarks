{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# Semi-structured RAG\n",
    "\n",
    "Let's evaluate your architecture on a small semi-structured Q&A dataset. This dataset is composed of QA pairs over pdfs that contain tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49db759-7ce6-4ab7-a58f-7fc3a6a7c8ec",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "We will install quite a few prerequisites for this example since we are comparing various techinques and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain_benchmarks\n",
    "# %pip install -U langchain langsmith langchainhub unstructured chromadb openai huggingface pandas langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae13f6-cd40-41e6-bd02-bd683e91cbff",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"sk-...\"  # Your API key\n",
    "\n",
    "# Silence warnings from HuggingFace\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
   "metadata": {},
   "source": [
    "## Review Q&A Tasks\n",
    "\n",
    "The registry provides configurations to test out common architectures on curated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone_public_dataset, registry\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_langsmith\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     clone_public_dataset,\n\u001b[1;32m      4\u001b[0m     download_public_dataset,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Please keep this list sorted!\u001b[39;00m\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/registration.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Registry of environments for ease of access.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m email_task\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     LANGCHAIN_DOCS_TASK,\n\u001b[1;32m      6\u001b[0m     SEMI_STRUCTURED_EARNINGS_TASK,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Registry\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool_usage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     multiverse_math,\n\u001b[1;32m     11\u001b[0m     relational_data,\n\u001b[1;32m     12\u001b[0m     type_writer,\n\u001b[1;32m     13\u001b[0m     type_writer_26_funcs,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/rag/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGCHAIN_DOCS_TASK\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_eval_config\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Please keep this sorted\u001b[39;00m\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/rag/tasks/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_docs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGCHAIN_DOCS_TASK\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemi_structured_earnings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     SEMI_STRUCTURED_EARNINGS_TASK,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Please keep this sorted\u001b[39;00m\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/rag/tasks/langchain_docs/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_docs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m architectures, indexing\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_docs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGCHAIN_DOCS_TASK\n\u001b[1;32m      4\u001b[0m DATASET_ID \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m452ccafc-18e1-4314-885b-edd735f17b9d\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# ID of public LangChain Docs dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/rag/tasks/langchain_docs/indexing/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_benchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_docs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretriever_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     RETRIEVER_FACTORIES,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETRIEVER_FACTORIES\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m~/code/lc/langchain-benchmarks/langchain_benchmarks/rag/tasks/langchain_docs/indexing/retriever_registry.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Iterable, Optional\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671282f8-c455-4390-b018-e53bbd833093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = registry[\"Semi-structured Earnings\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clone_public_dataset(task.dataset_id, dataset_name=task.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fafb2-63d0-40b4-b803-0095c5b22ca6",
   "metadata": {},
   "source": [
    "### Now, index the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad4b23-fbd4-4ebc-b5a5-d3d05efd0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
    "docs = list(task.get_docs())\n",
    "retriever_factory = task.retriever_factories[\"basic\"]\n",
    "# Indexes the documents with the specified embeddings\n",
    "retriever = retriever_factory(embeddings, docs=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57efac89-12f9-47e3-b60f-65d9279ebc1e",
   "metadata": {},
   "source": [
    "### Time to evaluate\n",
    "\n",
    "We will compose our retriever with a simple Llama based LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bc360-d822-43a8-b6b7-ff66dc27caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer based solely on the retrieved documents below:\\n\\n<Documents>\\n{docs}</Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"{Question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatAnthropic(model=\"claude-2\")\n",
    "\n",
    "\n",
    "def create_chain(retriever):\n",
    "    return (\n",
    "        RunnableAssign({\"docs\": (lambda x: next(iter(x.values()))) | retriever})\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cacd9-e841-4c76-ac16-f3f0cf18df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.rag import get_eval_config\n",
    "\n",
    "client = Client()\n",
    "RAG_EVALUATION = get_eval_config()\n",
    "chain = create_chain(retriever)\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54ef6c-0194-410a-aae9-f30c2097548a",
   "metadata": {},
   "source": [
    "## Example processing the docs\n",
    "\n",
    "RAG apps are as good as the information they are able to retrieve. Let's try indexing the tables' summaries to\n",
    "improve the likelihood that they are retrieved whenever a user asks a relevant question.\n",
    "\n",
    "We will use unstructured's `partition_pdf` functionality and generate summaries using an LLM.\n",
    "\n",
    "You can define your own indexing pipeline to see how it impacts the downstream performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378eddb-0a8d-4179-8e9c-54343469eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are summarizing semi-structured tables or text in a pdf.\\n\\n```document\\n{doc}\\n```\",\n",
    "        ),\n",
    "        (\"user\", \"Write a concise summary.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Summary chain\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "\n",
    "def create_doc(x) -> Document:\n",
    "    return Document(\n",
    "        page_content=x[\"output\"],\n",
    "        metadata=x[\"doc\"].metadata,\n",
    "    )\n",
    "\n",
    "\n",
    "summarize_chain = (\n",
    "    {\"doc\": lambda x: x}\n",
    "    | RunnableAssign({\"prompt\": prompt})\n",
    "    | {\n",
    "        \"output\": itemgetter(\"prompt\") | model | StrOutputParser(),\n",
    "        \"doc\": itemgetter(\"doc\"),\n",
    "    }\n",
    "    | create_doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2f070-3b5a-4de0-b3da-ddfb6e6f8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = summarize_chain.batch(\n",
    "    [doc for doc in docs if doc.metadata[\"element_type\"] == \"table\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc0bf8-fa50-4be3-8d23-04f6129548e0",
   "metadata": {},
   "source": [
    "Index the documents and create the retriever. We will re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1ccf6-2c2f-46f2-838e-5a5bf89515f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes the documents with the specified embeddings\n",
    "retriever_with_summaries = retriever_factory(\n",
    "    embeddings,\n",
    "    docs=docs + summaries,\n",
    "    # Specify a unique transformation name to avoid local cache collisions with other indices.\n",
    "    transformation_name=\"table-summaries\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "We'll evaluate the new chain on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f08c4c-a738-4449-9190-5a4f0b65b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_2 = create_chain(retriever_with_summaries)\n",
    "\n",
    "test_run_with_summaries = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=chain_2,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a96dbc-9a38-4d65-87bd-1e027d2215dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
