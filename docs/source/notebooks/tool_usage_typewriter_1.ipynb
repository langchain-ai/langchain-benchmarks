{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac938479-e489-4b04-80d9-b1b550154122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "# Typewriter: Single Tool\n",
    "\n",
    "Let's see how to evaluate an agent's ability to use tools.\n",
    "\n",
    "    A task where the agent must type a given string one letter at a time.\n",
    "\n",
    "    In this variation of the task, the agent is given a single function,\n",
    "    that takes a letter as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aef2b32-a5df-421f-8be3-a2ef27372ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Typewriter (1 tool)                                         </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                                                            </td></tr>\n",
       "<tr><td>Dataset ID </td><td>https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d</td></tr>\n",
       "<tr><td>Description</td><td>Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\n",
       "\n",
       "The objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\n",
       "\n",
       "For example, if the string is &#x27;abc&#x27;, the tools &#x27;a&#x27;, &#x27;b&#x27;, and &#x27;c&#x27; must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.                                                                          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Typewriter (1 tool)', dataset_id='https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d', description=\"Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\\n\\nThe objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\", create_environment=<function get_environment at 0x7fae404d2dc0>, instructions=\"Repeat the given string using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must print the letters 'a', 'b', and 'c' one at a time and in that order. \")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Typewriter (1 tool)\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33a639-3caf-4314-8ea7-1c7c8b1d114d",
   "metadata": {},
   "source": [
    "Clone the dataset associaetd with this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Tool Usage - Typewriter (1 tool) already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/25850d74-d4e0-41ac-81a1-dfc78a79660b.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(task.dataset_id, dataset_name=task.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462f7b8-fd42-4613-ab5f-5f3cbbc37d28",
   "metadata": {},
   "source": [
    "Let's build an agent that we can use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6142cf4e-862c-47a3-aa75-81d7d3231308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'abc',\n",
       " 'output': 'a, b, c',\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'a'}, log=\"\\nInvoking: `type_letter` with `{'letter': 'a'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"letter\": \"a\"\\n}', 'name': 'type_letter'}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'b'}, log=\"\\nInvoking: `type_letter` with `{'letter': 'b'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"letter\": \"b\"\\n}', 'name': 'type_letter'}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'c'}, log=\"\\nInvoking: `type_letter` with `{'letter': 'c'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"letter\": \"c\"\\n}', 'name': 'type_letter'}})]),\n",
       "   'OK')],\n",
       " 'state': 'abc'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_benchmarks.tool_usage import agents\n",
    "\n",
    "agent_factory = agents.OpenAIAgentFactory(task, model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "# Let's test that our agent works\n",
    "agent = agent_factory.create()\n",
    "agent.invoke({\"question\": \"abc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "## Eval\n",
    "\n",
    "Let's evaluate an agent now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb32763c-79ab-426a-8fc6-bf8ebb0dd432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-crushing-trousers-4' at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/projects/p/df829a5b-a7f8-44bb-b68e-a21f9ea8330a?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool) at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/25850d74-d4e0-41ac-81a1-dfc78a79660b\n",
      "[------------------------------------------------->] 20/20\n",
      " Eval quantiles:\n",
      "                                     0.25        0.5       0.75       mean  \\\n",
      "Intermediate steps correctness   0.000000   0.000000   0.000000   0.050000   \n",
      "# steps / # expected steps       1.781250   2.500000   3.750000   2.825160   \n",
      "Correct Final State              0.000000   0.000000   0.000000   0.050000   \n",
      "correctness                      0.000000   0.000000   0.000000   0.050000   \n",
      "execution_time                  35.480222  35.480222  35.480222  35.480222   \n",
      "\n",
      "                                     mode  \n",
      "Intermediate steps correctness   0.000000  \n",
      "# steps / # expected steps       3.000000  \n",
      "Correct Final State              0.000000  \n",
      "correctness                      0.000000  \n",
      "execution_time                  35.480222  \n"
     ]
    }
   ],
   "source": [
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.tool_usage import STANDARD_AGENT_EVALUATOR\n",
    "\n",
    "client = Client()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=agent_factory.create,\n",
    "    evaluation=STANDARD_AGENT_EVALUATOR,\n",
    "    verbose=True,\n",
    "    tags=[\"gpt-3.5-turbo-16k\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b039225-01cf-481a-87a6-4e880e9b1dcd",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "\n",
    "You can take a look at the underlying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb19db1-43b8-4866-a3d2-f211ba92ab8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = test_run.to_dataframe()\n",
    "df = pd.json_normalize(df.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab5a8b9-a937-4537-b879-704284df4494",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"correctness\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7516ed-36b1-4c16-bf4a-cc49077460ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"num_expected_steps\"] = df[\"reference.expected_steps\"].apply(len)\n",
    "df[\"actual_number_of_steps\"] = df[\"output.intermediate_steps\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d7590d-20de-4768-ac90-adcdbfa70068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intermediate steps correctness</th>\n",
       "      <th># steps / # expected steps</th>\n",
       "      <th>Correct Final State</th>\n",
       "      <th>correctness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>input.question</th>\n",
       "      <th>output.question</th>\n",
       "      <th>output.output</th>\n",
       "      <th>output.intermediate_steps</th>\n",
       "      <th>output.state</th>\n",
       "      <th>reference.state</th>\n",
       "      <th>reference.reference</th>\n",
       "      <th>reference.expected_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.480222</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b\\nc</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>abc</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>[type_letter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.480222</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aabacaaaaaaaaaa</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>[type_letter, type_letter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.480222</td>\n",
       "      <td>aaa</td>\n",
       "      <td>aaa</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aaaaaaaaaaaaaaa</td>\n",
       "      <td>aaa</td>\n",
       "      <td>aaa</td>\n",
       "      <td>[type_letter, type_letter, type_letter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.480222</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>[type_letter, type_letter, type_letter, type_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.480222</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>d\\no</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'd'...</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>[type_letter, type_letter, type_letter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intermediate steps correctness  # steps / # expected steps  \\\n",
       "0                               0                        3.00   \n",
       "1                               0                        7.50   \n",
       "2                               0                        5.00   \n",
       "3                               0                        3.75   \n",
       "4                               1                        1.00   \n",
       "\n",
       "   Correct Final State  correctness  execution_time input.question  \\\n",
       "0                    0            0       35.480222              a   \n",
       "1                    0            0       35.480222             aa   \n",
       "2                    0            0       35.480222            aaa   \n",
       "3                    0            0       35.480222           aaaa   \n",
       "4                    1            0       35.480222            dog   \n",
       "\n",
       "  output.question                                      output.output  \\\n",
       "0               a                                               b\\nc   \n",
       "1              aa  Agent stopped due to iteration limit or time l...   \n",
       "2             aaa  Agent stopped due to iteration limit or time l...   \n",
       "3            aaaa  Agent stopped due to iteration limit or time l...   \n",
       "4             dog                                               d\\no   \n",
       "\n",
       "                           output.intermediate_steps     output.state  \\\n",
       "0  [(tool='type_letter' tool_input={'letter': 'a'...              abc   \n",
       "1  [(tool='type_letter' tool_input={'letter': 'a'...  aabacaaaaaaaaaa   \n",
       "2  [(tool='type_letter' tool_input={'letter': 'a'...  aaaaaaaaaaaaaaa   \n",
       "3  [(tool='type_letter' tool_input={'letter': 'a'...  aaaaaaaaaaaaaaa   \n",
       "4  [(tool='type_letter' tool_input={'letter': 'd'...              dog   \n",
       "\n",
       "  reference.state reference.reference  \\\n",
       "0               a                   a   \n",
       "1              aa                  aa   \n",
       "2             aaa                 aaa   \n",
       "3            aaaa                aaaa   \n",
       "4             dog                 dog   \n",
       "\n",
       "                            reference.expected_steps  \n",
       "0                                      [type_letter]  \n",
       "1                         [type_letter, type_letter]  \n",
       "2            [type_letter, type_letter, type_letter]  \n",
       "3  [type_letter, type_letter, type_letter, type_l...  \n",
       "4            [type_letter, type_letter, type_letter]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
