{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9df2ed-3496-45c6-8b1b-e12776a02a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Tool Usage tasks are designed to evaluate how well an agent can use tools to accomplish an objective.\n",
    "\n",
    "Each task defines an environment in which the agent operates. The environment consists of a set of tools and a way to read the state of the environment (more on that below).\n",
    "\n",
    "The tasks allow you to stress test the agent in different ways:\n",
    "\n",
    "* Can the agent use a single tool effectively?\n",
    "* Can the agent use more than 10 tools effectively?\n",
    "* Can the agent correctly incorporate information returned by the tool (and ignore internal knowledge)?\n",
    "\n",
    "To help in this evaluation, each task is associated with a LangSmith dataset that includes input/output examples of varying difficulties.\n",
    "\n",
    "## Schema\n",
    "\n",
    "To make it possible to evaluate different agent implementations, we're using a standardized schema, we'll illustrate it with the following example taken from tool usage.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Each task corresponds to a LangSmith dataset with the following schema:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "|     name    |     type    |     meaning            |\n",
    "| ----------- | ----------- | -----------------------|\n",
    "| question    | str         | the user question      |\n",
    "\n",
    "\n",
    "Outputs:\n",
    "\n",
    "|     name      |     type        |     meaning                                            |\n",
    "| ------------- | --------------- | ------------------------------------------------------|\n",
    "| reference     | str             | the expected answer                                   |\n",
    "| expected_steps| List[str]       | the list of tools that should be invoked              |\n",
    "| order_matters | bool            | whether the tools should be invoked in the specific order |\n",
    "| state         | Optional[Any]   | the state of the system after the agent has taken its actions |\n",
    "\n",
    "\n",
    "\n",
    "Here's an [example](https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d/e82a0faf-00b9-40a5-a0e3-9723d923e58e/e) contains the following keys/values:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": {\"question\": \"weather in LA right now?\"},\n",
    "  \"output\": {\n",
    "      \"reference\": \"Sunny, Temperature: 75Â°F\",\n",
    "      \"order_matters\": true,\n",
    "      \"expected_steps\": [\n",
    "        \"find_locations_by_name\",\n",
    "        \"get_current_weather_for_location\"\n",
    "      ],\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Agent\n",
    "\n",
    "To work with the evaluators provided by LangChain Benchmarks (of course you're free to write your own evaluators!).\n",
    "\n",
    "An agent must accept `question` as an input and return:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"output\": \"It's super sunny. Like 75F\", // the output from the agent\n",
    "    \"intermediate_steps\": [... \"find_locations_by_name\" ...], // list of the intermediate steps taken by the agent (see format in LangChain)\n",
    "    \"state\": .., // Can be anything, this is the state fo the environment after the agent has taken all of its actions (optional key)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478781d-80ad-44ab-a0f8-1fc3d8c0f14d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tasks\n",
    "\n",
    "You can check an up-to-date list of tool usage tasks in the registry:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9b82fc-b689-4a25-b718-99ecc2fc6867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                              </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Tool Usage - Typewriter (1 tool)  </td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d\" target=\"_blank\" rel=\"noopener\">59577193-8938-4ccf-92a7-e8a96bcf4f86</a></td><td>Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\n",
       "\n",
       "The objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.              </td></tr>\n",
       "<tr><td>Tool Usage - Typewriter (26 tools)</td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
       "\n",
       "The objective of this task is to evaluate the model's ability the use tools\n",
       "for a simple repetition task.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
       "\n",
       "This is a variation of the typer writer task, where 26 parameterless tools are\n",
       "given instead of a single tool that takes a letter as an argument.              </td></tr>\n",
       "<tr><td>Tool Usage - Relational Data      </td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d\" target=\"_blank\" rel=\"noopener\">1d89f4b3-5f73-48cf-a127-2fdeb22f6d84</a></td><td>Environment with fake data about users and their locations and favorite foods.\n",
       "\n",
       "The environment provides a set of tools that can be used to query the data.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\n",
       "\n",
       "The dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\n",
       "\n",
       "Each example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\n",
       "\n",
       "Success is measured by the ability to answer the question correctly, and efficiently.              </td></tr>\n",
       "<tr><td>Multiverse Math                   </td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/47ed57bc-e852-4f84-a23e-cce4793864e9/d\" target=\"_blank\" rel=\"noopener\">47ed57bc-e852-4f84-a23e-cce4793864e9</a></td><td>An environment that contains a few basic math operations, but with altered results.\n",
       "\n",
       "For example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.\n",
       "\n",
       "This task is associated with 20 test examples.              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[ToolUsageTask(name='Tool Usage - Typewriter (1 tool)', dataset_id='https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d', description=\"Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\\n\\nThe objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\", create_environment=<function get_environment at 0x7b3a9f5fad40>, instructions=\"Repeat the given string using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must print the letters 'a', 'b', and 'c' one at a time and in that order. \", eval_params={'output_evaluation': 'none'}), ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x7b3a9f5fb240>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\", eval_params={'output_evaluation': 'none'}), ToolUsageTask(name='Tool Usage - Relational Data', dataset_id='https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d', description='Environment with fake data about users and their locations and favorite foods.\\n\\nThe environment provides a set of tools that can be used to query the data.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\\n\\nThe dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\\n\\nEach example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\\n\\nSuccess is measured by the ability to answer the question correctly, and efficiently.\\n', create_environment=<function get_environment at 0x7b3a9f5fa840>, instructions=\"Please answer the user's question by using the tools provided. Do not guess the answer. Keep in mind that entities like users,foods and locations have both a name and an ID, which are not the same.\", eval_params={}), ToolUsageTask(name='Multiverse Math', dataset_id='https://smith.langchain.com/public/47ed57bc-e852-4f84-a23e-cce4793864e9/d', description='An environment that contains a few basic math operations, but with altered results.\\n\\nFor example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.\\n\\nThis task is associated with 20 test examples.\\n', create_environment=<function get_environment at 0x7b3a9f5fa200>, instructions='You are requested to solve math questions in an alternate mathematical universe. The operations have been altered to yield different results than expected. Do not guess the answer or rely on your  innate knowledge of math. Use the provided tools to answer the question. While associativity and commutativity apply, distributivity does not. Answer the question using the fewest possible tools. Only include the numeric response without any clarifications.', eval_params={'output_evaluation': 'qa_math_without_question'})])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_benchmarks import registry\n",
    "\n",
    "registry.filter(Type=\"ToolUsageTask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54cdd3-67f6-43ba-a929-1a6ed1b01296",
   "metadata": {},
   "source": [
    "Let's understand what a tool usage task is in a bit more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7543739b-d212-4249-9b4a-fc406a58c9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Typewriter (26 tools)                                                                                                                         </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID </td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td></tr>\n",
       "<tr><td>Description</td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
       "\n",
       "The objective of this task is to evaluate the model's ability the use tools\n",
       "for a simple repetition task.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
       "\n",
       "This is a variation of the typer writer task, where 26 parameterless tools are\n",
       "given instead of a single tool that takes a letter as an argument.                                                                                                                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x7b3a9f5fb240>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\", eval_params={'output_evaluation': 'none'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Typewriter (26 tools)\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d6c77-8ed0-41d0-a7f5-303356cca4af",
   "metadata": {},
   "source": [
    "Tool usage tasks are associated with an environment\n",
    "\n",
    "---------\n",
    "```python\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ToolUsageEnvironment:\n",
    "    \"\"\"An instance of an environment for tool usage.\"\"\"\n",
    "\n",
    "    tools: List[BaseTool]\n",
    "    \"\"\"The tools that can be used in the environment.\"\"\"\n",
    "\n",
    "    read_state: Optional[Callable[[], Any]] = None\n",
    "    \"\"\"A function that returns the current state of the environment.\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b99c2-82b1-4eb5-87cb-5891d0b16a4b",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "Here, we'll dig into the typewriter task a bit to explain what the environment state represents.\n",
    "\n",
    "The typewrite task has 26 tools each of which prints a letter on a piece of virtual paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f201dbbe-7d92-4bc7-b4b5-ea8901dd2970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='a', description='a() -> str - Run to Type the letter \"a\".', args_schema=<class 'pydantic.v1.main.aSchema'>, func=<function _create_typing_func.<locals>.func at 0x7b3a9f62c9a0>),\n",
       " StructuredTool(name='b', description='b() -> str - Run to Type the letter \"b\".', args_schema=<class 'pydantic.v1.main.bSchema'>, func=<function _create_typing_func.<locals>.func at 0x7b3a9f62c5e0>),\n",
       " StructuredTool(name='c', description='c() -> str - Run to Type the letter \"c\".', args_schema=<class 'pydantic.v1.main.cSchema'>, func=<function _create_typing_func.<locals>.func at 0x7b3a9f62cae0>),\n",
       " StructuredTool(name='d', description='d() -> str - Run to Type the letter \"d\".', args_schema=<class 'pydantic.v1.main.dSchema'>, func=<function _create_typing_func.<locals>.func at 0x7b3a9f62cb80>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = task.create_environment()\n",
    "env.tools[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07957ee-ae52-47d4-a4ff-aa99d4d9bdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools[0].invoke({})  # Invoke a()\n",
    "env.tools[0].invoke({})  # invoke a()\n",
    "env.tools[2].invoke({})  # invoke c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fbb9b6-00f6-4445-b480-00eed6b5b3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aac'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.read_state()  # Shows the content of the virtual paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39b9b3-d4da-49bc-b3db-8a4165b1db55",
   "metadata": {},
   "source": [
    "## Create an Agent!\n",
    "\n",
    "Now that you know how the test environment works, let's create an agent that we can test!\n",
    "\n",
    "Because an agent interacts with the environment via tools and can change the state of the environment during the course of an agent run, what we actually want is the ability to create a fresh agent and a fresh environment for each test run.\n",
    "\n",
    "We'll do this using a factory. A factory is just a fancy name in computer science for an object that can create other objects. In this case, we'll have an Agent Factory that we can call and it'll create a fresh agent for us on each call.\n",
    "\n",
    "We'll use the StandardAgentFactory which under the hood creates a standard LangChain [tool calling agent](https://python.langchain.com/docs/modules/agents/agent_types/tool_calling/). It can be used with any [Chat Model that support tool calling](https://python.langchain.com/docs/integrations/chat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db65c253-7710-4c7b-b968-0662ec089030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_benchmarks.tool_usage.agents import StandardAgentFactory\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"{instructions}\"),  # Populated from task.instructions automatically\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),  # Each evaluation example is associated with a question\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),  # Space for the agent to do work\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent_factory = StandardAgentFactory(task, model, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99a9bd-fa3e-4401-9062-77dbcff30d5c",
   "metadata": {},
   "source": [
    "Here, were the instructions for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1f0a3d-fed6-41f7-8825-08787a57ad98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9de5d-185b-4776-9ee9-112a2db32139",
   "metadata": {},
   "source": [
    "Let's test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce67d619-fa99-4c15-bc53-3fb08b40a201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `a` with `{}`\n",
      "responded: [{'text': '<thinking>\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\n</thinking>', 'type': 'text'}, {'id': 'toolu_01MQ6oTx2j2uNGCR5LBVeKui', 'input': {}, 'name': 'a', 'type': 'tool_use'}, {'id': 'toolu_01AytT1jvNNR67VodMkhbq7r', 'input': {}, 'name': 'b', 'type': 'tool_use'}, {'id': 'toolu_015VkTYUV5hWcobtduqssi9k', 'input': {}, 'name': 'c', 'type': 'tool_use'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mOK\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `b` with `{}`\n",
      "responded: [{'text': '<thinking>\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\n</thinking>', 'type': 'text'}, {'id': 'toolu_01MQ6oTx2j2uNGCR5LBVeKui', 'input': {}, 'name': 'a', 'type': 'tool_use'}, {'id': 'toolu_01AytT1jvNNR67VodMkhbq7r', 'input': {}, 'name': 'b', 'type': 'tool_use'}, {'id': 'toolu_015VkTYUV5hWcobtduqssi9k', 'input': {}, 'name': 'c', 'type': 'tool_use'}]\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mOK\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `c` with `{}`\n",
      "responded: [{'text': '<thinking>\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\n</thinking>', 'type': 'text'}, {'id': 'toolu_01MQ6oTx2j2uNGCR5LBVeKui', 'input': {}, 'name': 'a', 'type': 'tool_use'}, {'id': 'toolu_01AytT1jvNNR67VodMkhbq7r', 'input': {}, 'name': 'b', 'type': 'tool_use'}, {'id': 'toolu_015VkTYUV5hWcobtduqssi9k', 'input': {}, 'name': 'c', 'type': 'tool_use'}]\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mOK\u001b[0m\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import globals\n",
    "\n",
    "globals.set_verbose(True)\n",
    "agent = agent_factory()\n",
    "agent.invoke({\"question\": \"abc\"})\n",
    "globals.set_verbose(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bce984-7c9c-4f6e-a51b-01c3e2b6e00a",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "How does one evaluate an agent? Given a particular task and input, an agent uses tools to produce an output AND/OR change the state of the environment.\n",
    "\n",
    "To evaluate an agent, we can check the following:\n",
    "\n",
    "1. Did the agent use the expected tools?\n",
    "2. Did the agent use the tools in the most effective way; e.g., was the order of tool invocation correct?\n",
    "3. Did the environment end up in the correct final state after the agent used the tools? (e.g., does my calendar contain all the scheduled meetings?)\n",
    "4. Did the agent output match the expected reference output?\n",
    "\n",
    "Each task is associated with a standard evaluator that does evaluation that's appropriate for the task; for example,\n",
    "\n",
    "1. Use an LLM to grade Compare output to reference using an LLM that grades the response.\n",
    "2. Compare equality of expected_steps to the list of tools in intermediate_steps -- simple list equality\n",
    "3. Compare the state of the environment against expected state (if present in the dataset and in the agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e5817-3b9d-4a1e-8ee8-692d39aa68ca",
   "metadata": {},
   "source": [
    "Each task is associated with its own task specific evaluator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c88bd6e1-f77e-4668-a143-096929e897ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunEvalConfig(evaluators=[], custom_evaluators=[<langchain_benchmarks.tool_usage.evaluators.AgentTrajectoryEvaluator object at 0x7b3a9ea5b110>], batch_evaluators=None, reference_key=None, prediction_key=None, input_key=None, eval_llm=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_config = task.get_eval_config()\n",
    "eval_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c7f91-9bb3-44b5-802d-f9f444ddeff9",
   "metadata": {},
   "source": [
    "Set up code to run against all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0770b442-f96a-4670-a4f7-3093f24fb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "\n",
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks import (\n",
    "    __version__,\n",
    "    clone_public_dataset,\n",
    "    model_registry,\n",
    "    registry,\n",
    ")\n",
    "from langchain_benchmarks.rate_limiting import RateLimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cbded4-5ab5-4b9b-9e88-77b24d3b750c",
   "metadata": {},
   "source": [
    "Create an experiment ID. we'll use it to tag our runs, which we can later use to retrieve run data from LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23208e3-01d1-4e83-9e4a-59544828f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = uuid.uuid4().hex[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83050cfc-f50f-4c63-8257-07e7688a54c4",
   "metadata": {},
   "source": [
    "Run evaluation against all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3463b-1c9f-494b-bcbd-1dc1760ebf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()  # Launch langsmith client for cloning datasets\n",
    "today = datetime.date.today().isoformat()\n",
    "\n",
    "# You can use an optional rate limiter to rate limit your requests!\n",
    "rate_limiter = RateLimiter(requests_per_second=1)\n",
    "\n",
    "\n",
    "# Set up 2-tuples of (model name, model instance)\n",
    "# You can update this list with any model that supports tool calling.\n",
    "# See list here: https://python.langchain.com/docs/integrations/chat/\n",
    "tests = [\n",
    "    (\n",
    "        \"claude-3-haiku-20240307\",\n",
    "        ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0),\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for task in registry.tasks:\n",
    "    if task.type != \"ToolUsageTask\":\n",
    "        continue\n",
    "\n",
    "    dataset_name = task.name + f\" ({today})\"\n",
    "    clone_public_dataset(task.dataset_id, dataset_name=dataset_name)\n",
    "\n",
    "    for model_name, model in tests:\n",
    "        print()\n",
    "        print(f\"Benchmarking {task.name} with model: {model_name}\")\n",
    "        eval_config = task.get_eval_config()\n",
    "\n",
    "        agent_factory = StandardAgentFactory(\n",
    "            task, model, prompt, rate_limiter=rate_limiter\n",
    "        )\n",
    "\n",
    "        client.run_on_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            llm_or_chain_factory=agent_factory,\n",
    "            evaluation=eval_config,\n",
    "            verbose=False,\n",
    "            project_name=f\"{model_name}-{task.name}-{today}-{experiment_id}\",\n",
    "            concurrency_level=5,\n",
    "            project_metadata={\n",
    "                \"model\": model_name,\n",
    "                \"id\": experiment_uuid,\n",
    "                \"task\": task.name,\n",
    "                \"date\": today,\n",
    "                \"langchain_benchmarks_version\": __version__,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6505-693d-46e5-9ed1-e33e0044b040",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "The following sections demonstrate slightly more \"advanced\" usage if you want to completely customize the agent runtime in a way that is compatible with our test runner.\n",
    "\n",
    "We'll also apply an adapter to the agent which will will capture its inputs and outputs (e.g, add information the agent's environment at the end of the run) so that it we can evaluate it.\n",
    "\n",
    "### Custom Agent Factory\n",
    "\n",
    "If you want even more configurability beyond what the `CustomRunnableAgentFactory` provides, you can create your owne `AgentFactory` using the following pattern.\n",
    "\n",
    "The `AgentExecutor` should accept `question` as an input and include the fields `output`, `intermediate_steps` and potentially `state` in its response -- for this we\n",
    "will wrap the agent executor in an adapter (`apply_agent_executor_adapter`) that will help match the expected schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69351864-2e97-43df-81ae-5067cbf5e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_benchmarks.schema import ExtractionTask\n",
    "from langchain_benchmarks.tool_usage.agents import apply_agent_executor_adapter\n",
    "\n",
    "\n",
    "class CustomAgentFactory:\n",
    "    def __init__(\n",
    "        self,\n",
    "        task: ExtractionTask,\n",
    "        *,\n",
    "        # It can be useful to add a rate-limiter\n",
    "        # which will limit ther number of requests per second\n",
    "        # when running evaluation.\n",
    "        rate_limiter: Optional[RateLimiter] = None,\n",
    "    ) -> None:\n",
    "        self.task = task\n",
    "        self.rate_limiter = rate_limiter\n",
    "\n",
    "    def __call__(self):\n",
    "        # This factory creates a new environment for every agent run.\n",
    "        # The reason is that the environment may be associated with an environment state (e.g., typewriter)\n",
    "        # which is changed by the actions of the agent.\n",
    "        # At the end of the run, the environment state will be read.\n",
    "        env = task.create_environment()  # Create a new environment for every agent run!\n",
    "        tools = env.tools\n",
    "        model = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=0)\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.task.instructions),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"{question}\",\n",
    "                ),  # Populated from task.instructions automatically\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # This is the standard tool calling agent implementation\n",
    "        # Feel free to replace it with any other implementation you want!\n",
    "        # https://python.langchain.com/docs/modules/agents/how_to/custom_agent/\n",
    "        agent = create_tool_calling_agent(model, env.tools, prompt)\n",
    "\n",
    "        if self.rate_limiter:\n",
    "            agent = with_rate_limit(agent, self.rate_limiter)\n",
    "\n",
    "        executor = AgentExecutor(\n",
    "            agent=agent,\n",
    "            tools=env.tools,\n",
    "            handle_parsing_errors=True,\n",
    "            return_intermediate_steps=True,\n",
    "        )\n",
    "\n",
    "        # Apply the adapters so that inputs and outputs match dataset schema\n",
    "        # state_reader automatically adds the state of the environment at the end of the run.\n",
    "        return apply_agent_executor_adapter(executor, state_reader=env.read_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a96a6f-812b-4b0e-83c5-d001bf50851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Typewriter (26 tools)                                                                                                                         </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID </td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td></tr>\n",
       "<tr><td>Description</td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
       "\n",
       "The objective of this task is to evaluate the model's ability the use tools\n",
       "for a simple repetition task.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
       "\n",
       "This is a variation of the typer writer task, where 26 parameterless tools are\n",
       "given instead of a single tool that takes a letter as an argument.                                                                                                                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x78972c6c3060>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\", eval_params={'output_evaluation': 'none'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7bd4af3-c0f1-4308-abbf-330d7497b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_agent_factory = CustomAgentFactory(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b69b7c-4294-47d1-85d7-47d718945898",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = custom_agent_factory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac24ef5-d3ca-41aa-b888-7ebcd8a92ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'abc',\n",
       " 'output': [],\n",
       " 'intermediate_steps': [(ToolAgentAction(tool='a', tool_input={}, log='\\nInvoking: `a` with `{}`\\nresponded: [{\\'text\\': \\'<thinking>\\\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\\\n</thinking>\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_016f6CZwwFmdz2h8KbdGRVjj\\', \\'input\\': {}, \\'name\\': \\'a\\', \\'type\\': \\'tool_use\\'}, {\\'id\\': \\'toolu_01JvfeTpU3hEuS7PknFk5a8S\\', \\'input\\': {}, \\'name\\': \\'b\\', \\'type\\': \\'tool_use\\'}, {\\'id\\': \\'toolu_01NbBCY5Fg62RsyAAUd4n2g1\\', \\'input\\': {}, \\'name\\': \\'c\\', \\'type\\': \\'tool_use\\'}]\\n\\n', message_log=[AIMessageChunk(content=[{'text': '<thinking>\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\n</thinking>', 'type': 'text'}, {'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj', 'input': {}, 'name': 'a', 'type': 'tool_use'}, {'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S', 'input': {}, 'name': 'b', 'type': 'tool_use'}, {'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1', 'input': {}, 'name': 'c', 'type': 'tool_use'}], id='run-42ea263e-e52a-4fc7-8aa3-71e16a9db42b', tool_calls=[{'name': 'a', 'args': {}, 'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj'}, {'name': 'b', 'args': {}, 'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S'}, {'name': 'c', 'args': {}, 'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1'}], tool_call_chunks=[{'name': 'a', 'args': '{}', 'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj', 'index': 0}, {'name': 'b', 'args': '{}', 'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S', 'index': 1}, {'name': 'c', 'args': '{}', 'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1', 'index': 2}])], tool_call_id='toolu_016f6CZwwFmdz2h8KbdGRVjj'),\n",
       "   'OK'),\n",
       "  (ToolAgentAction(tool='b', tool_input={}, log='\\nInvoking: `b` with `{}`\\nresponded: [{\\'text\\': \\'<thinking>\\\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\\\n</thinking>\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_016f6CZwwFmdz2h8KbdGRVjj\\', \\'input\\': {}, \\'name\\': \\'a\\', \\'type\\': \\'tool_use\\'}, {\\'id\\': \\'toolu_01JvfeTpU3hEuS7PknFk5a8S\\', \\'input\\': {}, \\'name\\': \\'b\\', \\'type\\': \\'tool_use\\'}, {\\'id\\': \\'toolu_01NbBCY5Fg62RsyAAUd4n2g1\\', \\'input\\': {}, \\'name\\': \\'c\\', \\'type\\': \\'tool_use\\'}]\\n\\n', message_log=[AIMessageChunk(content=[{'text': '<thinking>\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\n</thinking>', 'type': 'text'}, {'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj', 'input': {}, 'name': 'a', 'type': 'tool_use'}, {'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S', 'input': {}, 'name': 'b', 'type': 'tool_use'}, {'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1', 'input': {}, 'name': 'c', 'type': 'tool_use'}], id='run-42ea263e-e52a-4fc7-8aa3-71e16a9db42b', tool_calls=[{'name': 'a', 'args': {}, 'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj'}, {'name': 'b', 'args': {}, 'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S'}, {'name': 'c', 'args': {}, 'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1'}], tool_call_chunks=[{'name': 'a', 'args': '{}', 'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj', 'index': 0}, {'name': 'b', 'args': '{}', 'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S', 'index': 1}, {'name': 'c', 'args': '{}', 'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1', 'index': 2}])], tool_call_id='toolu_01JvfeTpU3hEuS7PknFk5a8S'),\n",
       "   'OK'),\n",
       "  (ToolAgentAction(tool='c', tool_input={}, log='\\nInvoking: `c` with `{}`\\nresponded: [{\\'text\\': \\'<thinking>\\\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\\\n</thinking>\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_016f6CZwwFmdz2h8KbdGRVjj\\', \\'input\\': {}, \\'name\\': \\'a\\', \\'type\\': \\'tool_use\\'}, {\\'id\\': \\'toolu_01JvfeTpU3hEuS7PknFk5a8S\\', \\'input\\': {}, \\'name\\': \\'b\\', \\'type\\': \\'tool_use\\'}, {\\'id\\': \\'toolu_01NbBCY5Fg62RsyAAUd4n2g1\\', \\'input\\': {}, \\'name\\': \\'c\\', \\'type\\': \\'tool_use\\'}]\\n\\n', message_log=[AIMessageChunk(content=[{'text': '<thinking>\\nTo repeat the string \"abc\", I need to call the a(), b(), and c() functions in that order. No parameters are required for these functions.\\n</thinking>', 'type': 'text'}, {'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj', 'input': {}, 'name': 'a', 'type': 'tool_use'}, {'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S', 'input': {}, 'name': 'b', 'type': 'tool_use'}, {'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1', 'input': {}, 'name': 'c', 'type': 'tool_use'}], id='run-42ea263e-e52a-4fc7-8aa3-71e16a9db42b', tool_calls=[{'name': 'a', 'args': {}, 'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj'}, {'name': 'b', 'args': {}, 'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S'}, {'name': 'c', 'args': {}, 'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1'}], tool_call_chunks=[{'name': 'a', 'args': '{}', 'id': 'toolu_016f6CZwwFmdz2h8KbdGRVjj', 'index': 0}, {'name': 'b', 'args': '{}', 'id': 'toolu_01JvfeTpU3hEuS7PknFk5a8S', 'index': 1}, {'name': 'c', 'args': '{}', 'id': 'toolu_01NbBCY5Fg62RsyAAUd4n2g1', 'index': 2}])], tool_call_id='toolu_01NbBCY5Fg62RsyAAUd4n2g1'),\n",
       "   'OK')],\n",
       " 'state': 'abc'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"question\": \"abc\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
