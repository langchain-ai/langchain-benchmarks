{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6728b05f-e3bb-487a-8818-e0d5d18b5501",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/tool_usage/intro.ipynb)\n",
    "\n",
    "Tool Usage tasks are designed to evaluate how well an agent can use tools to accomplish an objective.\n",
    "\n",
    "Each task defines an environment within which the agent operates. The environment consists of a set of pre-defined tools and a way to read the state of the environment (more on that below).\n",
    "\n",
    "Different asks define different environments, objectives and tools, allowing you to stress test different aspects of the agent:\n",
    "\n",
    "* Can the agent use a single tool effectively?\n",
    "* Can an agent use more than 10 tools effectively?\n",
    "* Can an agent correctly ignore what they know to use the output from tools effectively?\n",
    "\n",
    "To help in this evaluation, each task is associated with a LangSmith dataset that includes input/output examples of varying difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274faca-26fc-470b-8485-5a81b83e2c54",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7a63b-04f3-4121-9fe6-5ce772527e85",
   "metadata": {},
   "source": [
    "How does one evaluate an agent? Given a particular task and input, an agent uses tools to produce an output AND/OR change the state of the environment.\n",
    "\n",
    "To evaluate an agent, we can check the following:\n",
    "\n",
    "1. Did the agent use the expected tools?\n",
    "2. Did the agent use the tools in the most effective way; e.g., was the order of tool invocation correct?\n",
    "3. Did the environment end up in the correct final state after the agent used the tools? (e.g., does my calendar contain all the scheduled meetings?)\n",
    "4. Did the agent output match the expected reference output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea730c19-0ea7-475c-929a-1bce78a239c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Schema\n",
    "\n",
    "To make it possible to evaluate different agent implementations, we're using a standardized schema, we'll illustrate it with the following example taken from tool usage:\n",
    "\n",
    "### Dataset\n",
    "\n",
    "https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d/e82a0faf-00b9-40a5-a0e3-9723d923e58e/e\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": {\"question\": \"weather in LA right now?\"},  // User's question\n",
    "  \"output\": {\n",
    "      \"reference\": \"Sunny, Temperature: 75Â°F\",  // The expected answer for the output (when it exists)\n",
    "      \"order_matters\": true,  // Whether the order of expected steps was meaningful\n",
    "      \"expected_steps\": [ #  // list of which tools the agent should've invoked\n",
    "        \"find_locations_by_name\",\n",
    "        \"get_current_weather_for_location\"\n",
    "      ],\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Agent\n",
    "\n",
    "To work with the evaluators provided by LangChain Benchmarks (of course you're free to write your own evaluators!).\n",
    "\n",
    "An agent must accept `question` as an input and return:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"output\": \"It's super sunny. Like 75F\", // the output from the agent\n",
    "    \"intermediate_steps\": [... \"find_locations_by_name\" ...], // list of the intermediate steps taken by the agent (see format in LangChain)\n",
    "    \"state\": .., // Can be anything, this is the state fo the environment after the agent has taken all of its actions (optional key)\n",
    "}\n",
    "```\n",
    "\n",
    "## Standard Evaluators\n",
    "\n",
    "The different tasks are associated with standard evaluators.\n",
    "\n",
    "The standard agent evaluator does the following:\n",
    "\n",
    "1. Compare output to reference using an LLM that grades the response.\n",
    "2. Compare equality of exxpected_steps to the list of tools in intermediate_steps -- simple list equality\n",
    "3. Compare the state of the environment against expected state (if present in the dataset and in the agent)\n",
    "4. It does not use `order_matters` at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478781d-80ad-44ab-a0f8-1fc3d8c0f14d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tasks\n",
    "\n",
    "You can check an up-to-date list of tool usage tasks in the registry:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9b82fc-b689-4a25-b718-99ecc2fc6867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                              </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Tool Usage - Typewriter (1 tool)  </td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d\" target=\"_blank\" rel=\"noopener\">59577193-8938-4ccf-92a7-e8a96bcf4f86</a></td><td>Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\n",
       "\n",
       "The objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.              </td></tr>\n",
       "<tr><td>Tool Usage - Typewriter (26 tools)</td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
       "\n",
       "The objective of this task is to evaluate the model's ability the use tools\n",
       "for a simple repetition task.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
       "\n",
       "This is a variation of the typer writer task, where 26 parameterless tools are\n",
       "given instead of a single tool that takes a letter as an argument.              </td></tr>\n",
       "<tr><td>Tool Usage - Relational Data      </td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d\" target=\"_blank\" rel=\"noopener\">1d89f4b3-5f73-48cf-a127-2fdeb22f6d84</a></td><td>Environment with fake data about users and their locations and favorite foods.\n",
       "\n",
       "The environment provides a set of tools that can be used to query the data.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\n",
       "\n",
       "The dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\n",
       "\n",
       "Each example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\n",
       "\n",
       "Success is measured by the ability to answer the question correctly, and efficiently.              </td></tr>\n",
       "<tr><td>Multiverse Math                   </td><td>ToolUsageTask</td><td><a href=\"https://smith.langchain.com/public/594f9f60-30a0-49bf-b075-f44beabf546a/d\" target=\"_blank\" rel=\"noopener\">594f9f60-30a0-49bf-b075-f44beabf546a</a></td><td>An environment that contains a few basic math operations, but with altered results.\n",
       "\n",
       "For example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\n",
       "\n",
       "The objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[ToolUsageTask(name='Tool Usage - Typewriter (1 tool)', dataset_id='https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d', description=\"Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\\n\\nThe objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\", create_environment=<function get_environment at 0x7f9d728acee0>, instructions=\"Repeat the given string using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must print the letters 'a', 'b', and 'c' one at a time and in that order. \"), ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x7f9d728bb4c0>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\"), ToolUsageTask(name='Tool Usage - Relational Data', dataset_id='https://smith.langchain.com/public/1d89f4b3-5f73-48cf-a127-2fdeb22f6d84/d', description='Environment with fake data about users and their locations and favorite foods.\\n\\nThe environment provides a set of tools that can be used to query the data.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to answer questions about relational data.\\n\\nThe dataset contains 21 examples of varying difficulty. The difficulty is measured by the number of tools that need to be used to answer the question.\\n\\nEach example is composed of a question, a reference answer, and information about the sequence in which tools should be used to answer the question.\\n\\nSuccess is measured by the ability to answer the question correctly, and efficiently.\\n', create_environment=<function get_environment at 0x7f9d728aca60>, instructions=\"Please answer the user's question by using the tools provided. Do not guess the answer. Keep in mind that entities like users,foods and locations have both a name and an ID, which are not the same.\"), ToolUsageTask(name='Multiverse Math', dataset_id='https://smith.langchain.com/public/594f9f60-30a0-49bf-b075-f44beabf546a/d', description='An environment that contains a few basic math operations, but with altered results.\\n\\nFor example, multiplication of 5*3 will be re-interpreted as 5*3*1.1. The basic operations retain some basic properties, such as commutativity, associativity, and distributivity; however, the results are different than expected.\\n\\nThe objective of this task is to evaluate the ability to use the provided tools to solve simple math questions and ignore any innate knowledge about math.\\n', create_environment=<function get_environment at 0x7f9d728ac430>, instructions='You are requested to solve math questions in an alternate mathematical universe. The operations have been altered to yield different results than expected. Do not guess the answer or rely on your  innate knowledge of math. Use the provided tools to answer the question. While associativity and commutativity apply, distributivity does not. Answer the question using the fewest possible tools. Only include the numeric response without any clarifications.')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_benchmarks import registry\n",
    "\n",
    "registry.filter(Type=\"ToolUsageTask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54cdd3-67f6-43ba-a929-1a6ed1b01296",
   "metadata": {},
   "source": [
    "Let's understand what a tool usage task is in a bit more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7543739b-d212-4249-9b4a-fc406a58c9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Typewriter (26 tools)                                                                                                                         </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID </td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td></tr>\n",
       "<tr><td>Description</td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
       "\n",
       "The objective of this task is to evaluate the model's ability the use tools\n",
       "for a simple repetition task.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
       "\n",
       "This is a variation of the typer writer task, where 26 parameterless tools are\n",
       "given instead of a single tool that takes a letter as an argument.                                                                                                                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x7f9d728bb4c0>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Typewriter (26 tools)\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d6c77-8ed0-41d0-a7f5-303356cca4af",
   "metadata": {},
   "source": [
    "Tool usage tasks are associated with an environment\n",
    "\n",
    "---------\n",
    "```python\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ToolUsageEnvironment:\n",
    "    \"\"\"An instance of an environment for tool usage.\"\"\"\n",
    "\n",
    "    tools: List[BaseTool]\n",
    "    \"\"\"The tools that can be used in the environment.\"\"\"\n",
    "\n",
    "    read_state: Optional[Callable[[], Any]] = None\n",
    "    \"\"\"A function that returns the current state of the environment.\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b99c2-82b1-4eb5-87cb-5891d0b16a4b",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "Here, we'll dig into the typewriter task a bit to explain what the environment state represents.\n",
    "\n",
    "The typewrite task has 26 tools each of which prints a letter on a piece of virtual paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f201dbbe-7d92-4bc7-b4b5-ea8901dd2970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='a', description='a() -> str - Run to Type the letter \"a\".', args_schema=<class 'pydantic.v1.main.aSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f9d713a49d0>),\n",
       " StructuredTool(name='b', description='b() -> str - Run to Type the letter \"b\".', args_schema=<class 'pydantic.v1.main.bSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f9d713a4a60>),\n",
       " StructuredTool(name='c', description='c() -> str - Run to Type the letter \"c\".', args_schema=<class 'pydantic.v1.main.cSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f9d713a4af0>),\n",
       " StructuredTool(name='d', description='d() -> str - Run to Type the letter \"d\".', args_schema=<class 'pydantic.v1.main.dSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f9d713a4b80>)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = task.create_environment()\n",
    "\n",
    "env.tools[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4eb0c3f-4057-4439-aa79-1d9db87756cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.read_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e004ff6-d465-4632-a0bd-438b680c91db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools[3].invoke({})  # Invoke d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bbd6d6e-32a1-44d6-b3ff-f45d99e0727b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools[5].invoke({})  # invoke f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40fbb9b6-00f6-4445-b480-00eed6b5b3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.read_state()  # Shows the content of the virtual paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
