{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Typewriter: Single Tool\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/tool_usage/typewriter_1.ipynb)\n",
    "\n",
    "\n",
    "    In this task, an agent is given access to a single tool called \"type_letter\".\n",
    "    This tool takes one argument called \"letter\" which is expected to be a character.\n",
    "    \n",
    "    The agent must repeat the input string from the user, printing one\n",
    "    character a time on a piece of virtual paper.\n",
    "    \n",
    "    The agent is evaluated based on its ability to print the correct string using\n",
    "    the \"type_letter\" tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aef2b32-a5df-421f-8be3-a2ef27372ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Typewriter (1 tool)                                                                                                                           </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID </td><td><a href=\"https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d\" target=\"_blank\" rel=\"noopener\">59577193-8938-4ccf-92a7-e8a96bcf4f86</a></td></tr>\n",
       "<tr><td>Description</td><td>Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\n",
       "\n",
       "The objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.                                                                                                                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Typewriter (1 tool)', dataset_id='https://smith.langchain.com/public/59577193-8938-4ccf-92a7-e8a96bcf4f86/d', description=\"Environment with a single tool that accepts a single letter as input, and prints it on a piece of virtual paper.\\n\\nThe objective of this task is to evaluate the ability of the model to use the provided tools to repeat a given input string.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\", create_environment=<function get_environment at 0x7f53b5c5b430>, instructions=\"Repeat the given string using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must print the letters 'a', 'b', and 'c' one at a time and in that order. \")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Typewriter (1 tool)\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33a639-3caf-4314-8ea7-1c7c8b1d114d",
   "metadata": {},
   "source": [
    "Clone the dataset associaetd with this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Tool Usage - Typewriter (1 tool) already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/25850d74-d4e0-41ac-81a1-dfc78a79660b.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(task.dataset_id, dataset_name=task.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78a3e1-80da-4607-98c3-a99c2037e7ca",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "The environment consists of a single tool and a virtual paper.\n",
    "\n",
    "The tool accepts a single letter as an input and prints the leter on the virtual paper. If successful, the tool returns the output \"OK\".\n",
    "\n",
    "To determine what's written on the paper, one needs to read the environment state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e538ae-5cf2-4cd5-a312-25ee6924e869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = task.create_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5516a34b-1e9b-4f1e-9462-cfc4d5bc29f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='type_letter', description='type_letter(letter: str) -> str - Print the given letter on the paper.', args_schema=<class 'pydantic.v1.main.type_letterSchemaSchema'>, func=<function create_typer.<locals>.type_letter at 0x7f538cc0e040>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80501e1a-f1f6-4b38-8637-894503029d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool = env.tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f352e32-fdb6-4d9e-b1c4-3d78b4f50646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({'letter': 'a'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec9c2e68-b55e-4087-bc1a-c38f4cfd401b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({'letter': 'b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc5b174-25a4-4d5a-8535-56ecea62ea81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.read_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13d120-1bf9-481c-9392-c15ebdd9d77f",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462f7b8-fd42-4613-ab5f-5f3cbbc37d28",
   "metadata": {},
   "source": [
    "Let's build an agent that we can use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6142cf4e-862c-47a3-aa75-81d7d3231308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'abc',\n",
       " 'output': 'a, b, c',\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'a'}, log=\"\\nInvoking: `type_letter` with `{'letter': 'a'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"letter\": \"a\"\\n}', 'name': 'type_letter'}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'b'}, log=\"\\nInvoking: `type_letter` with `{'letter': 'b'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"letter\": \"b\"\\n}', 'name': 'type_letter'}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'c'}, log=\"\\nInvoking: `type_letter` with `{'letter': 'c'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"letter\": \"c\"\\n}', 'name': 'type_letter'}})]),\n",
       "   'OK')],\n",
       " 'state': 'abc'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_benchmarks.tool_usage import agents\n",
    "\n",
    "agent_factory = agents.OpenAIAgentFactory(task, model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "# Let's test that our agent works\n",
    "agent = agent_factory.create()\n",
    "agent.invoke({\"question\": \"abc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "## Eval\n",
    "\n",
    "Let's evaluate an agent now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb32763c-79ab-426a-8fc6-bf8ebb0dd432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-shiny-curve-39' at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/projects/p/c66bbd6e-cce5-461d-9287-97391bd2f668?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool) at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/25850d74-d4e0-41ac-81a1-dfc78a79660b\n",
      "[------------------------------------------------->] 20/20\n",
      " Eval quantiles:\n",
      "                                     0.25        0.5       0.75       mean  \\\n",
      "Intermediate steps correctness   1.000000   1.000000   1.000000   0.950000   \n",
      "# steps / # expected steps       1.000000   1.000000   1.000000   1.700000   \n",
      "Correct Final State              1.000000   1.000000   1.000000   0.950000   \n",
      "correctness                      1.000000   1.000000   1.000000   0.800000   \n",
      "execution_time                  34.058961  34.058961  34.058961  34.058961   \n",
      "\n",
      "                                     mode  \n",
      "Intermediate steps correctness   1.000000  \n",
      "# steps / # expected steps       1.000000  \n",
      "Correct Final State              1.000000  \n",
      "correctness                      1.000000  \n",
      "execution_time                  34.058961  \n"
     ]
    }
   ],
   "source": [
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.tool_usage import STANDARD_AGENT_EVALUATOR\n",
    "\n",
    "client = Client()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=agent_factory.create,\n",
    "    evaluation=STANDARD_AGENT_EVALUATOR,\n",
    "    verbose=True,\n",
    "    tags=[\"gpt-3.5-turbo-16k\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b039225-01cf-481a-87a6-4e880e9b1dcd",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "\n",
    "You can take a look at the underlying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb19db1-43b8-4866-a3d2-f211ba92ab8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = test_run.to_dataframe()\n",
    "df = pd.json_normalize(df.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab5a8b9-a937-4537-b879-704284df4494",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"correctness\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7516ed-36b1-4c16-bf4a-cc49077460ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"num_expected_steps\"] = df[\"reference.expected_steps\"].apply(len)\n",
    "df[\"actual_number_of_steps\"] = df[\"output.intermediate_steps\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d7590d-20de-4768-ac90-adcdbfa70068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intermediate steps correctness</th>\n",
       "      <th># steps / # expected steps</th>\n",
       "      <th>Correct Final State</th>\n",
       "      <th>correctness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>input.question</th>\n",
       "      <th>output.question</th>\n",
       "      <th>output.output</th>\n",
       "      <th>output.intermediate_steps</th>\n",
       "      <th>output.state</th>\n",
       "      <th>reference.state</th>\n",
       "      <th>reference.reference</th>\n",
       "      <th>reference.expected_steps</th>\n",
       "      <th>num_expected_steps</th>\n",
       "      <th>actual_number_of_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.058961</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>Agent stopped due to iteration limit or time l...</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aaaaaaaaaaaaaaa</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>[type_letter]</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.058961</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa\\naa</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>[type_letter, type_letter]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.058961</td>\n",
       "      <td>aaa</td>\n",
       "      <td>aaa</td>\n",
       "      <td>a\\na</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aaa</td>\n",
       "      <td>aaa</td>\n",
       "      <td>aaa</td>\n",
       "      <td>[type_letter, type_letter, type_letter]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.058961</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>a\\na</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'a'...</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>[type_letter, type_letter, type_letter, type_l...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.058961</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>d\\no\\ng</td>\n",
       "      <td>[(tool='type_letter' tool_input={'letter': 'd'...</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>[type_letter, type_letter, type_letter]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intermediate steps correctness  # steps / # expected steps  \\\n",
       "0                               0                        15.0   \n",
       "1                               1                         1.0   \n",
       "2                               1                         1.0   \n",
       "3                               1                         1.0   \n",
       "4                               1                         1.0   \n",
       "\n",
       "   Correct Final State  correctness  execution_time input.question  \\\n",
       "0                    0            0       34.058961              a   \n",
       "1                    1            1       34.058961             aa   \n",
       "2                    1            0       34.058961            aaa   \n",
       "3                    1            0       34.058961           aaaa   \n",
       "4                    1            1       34.058961            dog   \n",
       "\n",
       "  output.question                                      output.output  \\\n",
       "0               a  Agent stopped due to iteration limit or time l...   \n",
       "1              aa                                             aa\\naa   \n",
       "2             aaa                                               a\\na   \n",
       "3            aaaa                                               a\\na   \n",
       "4             dog                                            d\\no\\ng   \n",
       "\n",
       "                           output.intermediate_steps     output.state  \\\n",
       "0  [(tool='type_letter' tool_input={'letter': 'a'...  aaaaaaaaaaaaaaa   \n",
       "1  [(tool='type_letter' tool_input={'letter': 'a'...               aa   \n",
       "2  [(tool='type_letter' tool_input={'letter': 'a'...              aaa   \n",
       "3  [(tool='type_letter' tool_input={'letter': 'a'...             aaaa   \n",
       "4  [(tool='type_letter' tool_input={'letter': 'd'...              dog   \n",
       "\n",
       "  reference.state reference.reference  \\\n",
       "0               a                   a   \n",
       "1              aa                  aa   \n",
       "2             aaa                 aaa   \n",
       "3            aaaa                aaaa   \n",
       "4             dog                 dog   \n",
       "\n",
       "                            reference.expected_steps  num_expected_steps  \\\n",
       "0                                      [type_letter]                   1   \n",
       "1                         [type_letter, type_letter]                   2   \n",
       "2            [type_letter, type_letter, type_letter]                   3   \n",
       "3  [type_letter, type_letter, type_letter, type_l...                   4   \n",
       "4            [type_letter, type_letter, type_letter]                   3   \n",
       "\n",
       "   actual_number_of_steps  \n",
       "0                      15  \n",
       "1                       2  \n",
       "2                       3  \n",
       "3                       4  \n",
       "4                       3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
