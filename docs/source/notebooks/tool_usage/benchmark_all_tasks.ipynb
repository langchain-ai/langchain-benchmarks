{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba9f105-c48f-4d8c-8253-355ef13156b0",
   "metadata": {},
   "source": [
    "# Benchmark All\n",
    "\n",
    "Here, we'll run benchmarking against all tool usage task.\n",
    "\n",
    "Expand the models list to benchmark against different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadb9ef-e76a-4b48-85e4-f62c3957f502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "\n",
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks import clone_public_dataset, registry\n",
    "from langchain_benchmarks.tool_usage import agents\n",
    "from langchain_benchmarks.rate_limiting import RateLimiter, with_rate_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5c7ff-a00a-4004-a904-e65e18b6bfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests_per_minute = 50\n",
    "rate_limiter = RateLimiter(requests_per_second=requests_per_minute / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbc3ef-7a3f-430f-8b79-45af5861b3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Tool Usage - Typewriter (1 tool)_benchmarking_2023-12-12 already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/e959b972-9b0b-4035-ad63-e0314ffc58d6.\n",
      "\n",
      "Benchmarking Tool Usage - Typewriter (1 tool) with model: gpt-3.5-turbo-16k\n",
      "View the evaluation results for project 'Tool Usage - Typewriter (1 tool)_benchmarking_2023-12-12-gpt-3.5-turbo-16k-2710' at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/e959b972-9b0b-4035-ad63-e0314ffc58d6/compare?selectedSessions=6ba5fbb8-1ea7-46fd-86ec-e01d9c3dc913\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool)_benchmarking_2023-12-12 at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/e959b972-9b0b-4035-ad63-e0314ffc58d6\n",
      "[------------------------------------------------->] 20/20Dataset Tool Usage - Typewriter (26 tools)_benchmarking_2023-12-12 already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/0998cb45-72a5-4575-9a8f-3cc1a8c759af.\n",
      "\n",
      "Benchmarking Tool Usage - Typewriter (26 tools) with model: gpt-3.5-turbo-16k\n",
      "View the evaluation results for project 'Tool Usage - Typewriter (26 tools)_benchmarking_2023-12-12-gpt-3.5-turbo-16k-2710' at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/0998cb45-72a5-4575-9a8f-3cc1a8c759af/compare?selectedSessions=71fcbbf0-c1e1-4f9c-85ba-8f5574dc03ff\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (26 tools)_benchmarking_2023-12-12 at:\n",
      "https://smith.langchain.com/o/e081f11e-fbd2-41b4-9fa8-5d76c76ef854/datasets/0998cb45-72a5-4575-9a8f-3cc1a8c759af\n",
      "[----------->                                      ] 5/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b4e2139abd830cf764cc7419d532791f in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b4e2139abd830cf764cc7419d532791f in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b4e2139abd830cf764cc7419d532791f in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:49:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '1456', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999917', 'x-ratelimit-remaining-tokens_usage_based': '1999917', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '2ms', 'x-ratelimit-reset-tokens_usage_based': '2ms', 'x-request-id': 'b4e2139abd830cf764cc7419d532791f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '83471de0ccaa4cf9-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Chain failed for example eabcf07b-00bc-419f-9e32-42410b5d2cf9 with inputs {'question': 'horse'}\n",
      "Error Type: APIError, Message: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 34f828b3bbcc2d421d8f069f7eba9e21 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 34f828b3bbcc2d421d8f069f7eba9e21 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 34f828b3bbcc2d421d8f069f7eba9e21 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:49:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '1283', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '1999010', 'x-ratelimit-remaining-tokens_usage_based': '1999010', 'x-ratelimit-reset-requests': '32ms', 'x-ratelimit-reset-tokens': '29ms', 'x-ratelimit-reset-tokens_usage_based': '29ms', 'x-request-id': '34f828b3bbcc2d421d8f069f7eba9e21', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '83471e059cc04cf9-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------->                                   ] 6/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8b68a315d94df4645585730223d0a3c4 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8b68a315d94df4645585730223d0a3c4 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8b68a315d94df4645585730223d0a3c4 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:49:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '1340', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999915', 'x-ratelimit-remaining-tokens_usage_based': '1999915', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '2ms', 'x-ratelimit-reset-tokens_usage_based': '2ms', 'x-request-id': '8b68a315d94df4645585730223d0a3c4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '83471e1f6cbf4cf9-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------->                      ] 11/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 1d3a8b1298980e39a32d412390a8fc00 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 1d3a8b1298980e39a32d412390a8fc00 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 1d3a8b1298980e39a32d412390a8fc00 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:50:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '383', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999915', 'x-ratelimit-remaining-tokens_usage_based': '1999915', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '2ms', 'x-ratelimit-reset-tokens_usage_based': '2ms', 'x-request-id': '1d3a8b1298980e39a32d412390a8fc00', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '83471f27d8c94d14-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Chain failed for example c7be2209-cba8-4f8c-b5f5-8c99b74862a4 with inputs {'question': 'keyboard'}\n",
      "Error Type: APIError, Message: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 7ef4f0872ee71ff8a3d9b6fc020e6626 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 7ef4f0872ee71ff8a3d9b6fc020e6626 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 7ef4f0872ee71ff8a3d9b6fc020e6626 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:50:17 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '480', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999915', 'x-ratelimit-remaining-tokens_usage_based': '1999915', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '2ms', 'x-ratelimit-reset-tokens_usage_based': '2ms', 'x-request-id': '7ef4f0872ee71ff8a3d9b6fc020e6626', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '83471f440ed64d14-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------->          ] 16/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID af58d4a8c026da2b825d735784e28efa in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID af58d4a8c026da2b825d735784e28efa in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID af58d4a8c026da2b825d735784e28efa in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:51:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '474', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999861', 'x-ratelimit-remaining-tokens_usage_based': '1999861', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '4ms', 'x-ratelimit-reset-tokens_usage_based': '4ms', 'x-request-id': 'af58d4a8c026da2b825d735784e28efa', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '83472086efe04cff-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Chain failed for example fca94876-679e-4b1d-8658-d8c9fe10ca97 with inputs {'question': 'dictionary'}\n",
      "Error Type: APIError, Message: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 40d2a6af62ede19e5bd2b57075d3bfd6 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 40d2a6af62ede19e5bd2b57075d3bfd6 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 40d2a6af62ede19e5bd2b57075d3bfd6 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 12 Dec 2023 15:51:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'langchain', 'openai-processing-ms': '384', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-limit-tokens_usage_based': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999861', 'x-ratelimit-remaining-tokens_usage_based': '1999861', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '4ms', 'x-ratelimit-reset-tokens_usage_based': '4ms', 'x-request-id': '40d2a6af62ede19e5bd2b57075d3bfd6', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '834720a3bd414cff-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------------------->        ] 17/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example e361b334-e698-40ae-a488-82b7734ce8d0 with inputs {'question': 'school'}\n",
      "Error Type: Timeout, Message: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------------------------------->     ] 18/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------------------------->  ] 19/20"
     ]
    }
   ],
   "source": [
    "experiment_uuid = uuid.uuid4().hex[:4]\n",
    "models = [\"gpt-3.5-turbo-16k\"]\n",
    "client = Client()  # Launch langsmith client for cloning datasets\n",
    "today = datetime.date.today().isoformat()\n",
    "\n",
    "for task in registry:\n",
    "    dataset_name = task.name + f\"_benchmarking_{today}\"\n",
    "    clone_public_dataset(task.dataset_id, dataset_name=dataset_name)\n",
    "\n",
    "    if task.type != \"ToolUsageTask\":\n",
    "        continue\n",
    "    for model in models:\n",
    "        print()\n",
    "        print(f\"Benchmarking {task.name} with model: {model}\")\n",
    "        eval_config = task.get_eval_config()\n",
    "        agent_factory = agents.OpenAIAgentFactory(task, model=model, rate_limiter=rate_limiter)\n",
    "\n",
    "        client.run_on_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            llm_or_chain_factory=agent_factory,\n",
    "            evaluation=eval_config,\n",
    "            verbose=False,\n",
    "            project_name=f\"{dataset_name}-{model}-{experiment_uuid}\",\n",
    "            tags=[model],\n",
    "            concurrency_level=5,\n",
    "            project_metadata={\n",
    "                \"model\": model,\n",
    "                \"id\": experiment_uuid,\n",
    "                \"task\": task.name,\n",
    "                \"date\": today,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc6039-b383-4a18-bc6c-a6f9fade0f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
