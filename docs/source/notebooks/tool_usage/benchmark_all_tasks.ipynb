{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba9f105-c48f-4d8c-8253-355ef13156b0",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "Let's benchmark against all tool usage tasks. \n",
    "\n",
    "Expand the models list to benchmark with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a7483b-d08f-49fa-83da-619863171e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks import (\n",
    "    __version__,\n",
    "    clone_public_dataset,\n",
    "    model_registry,\n",
    "    registry,\n",
    ")\n",
    "from langchain_benchmarks.rate_limiting import RateLimiter\n",
    "from langchain_benchmarks.tool_usage.agents import (\n",
    "    CustomAgentFactory,\n",
    "    OpenAIAgentFactory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbe23b-a3b1-4607-929d-ea6e88b7085e",
   "metadata": {},
   "source": [
    "Prior to starting the tests, you may want to verify\n",
    "that the task that you're working with and the models are propelry defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfbcaa9-349c-4223-89be-4abff9cf76ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Repeat the given string using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must print the letters 'a', 'b', and 'c' one at a time and in that order. \\nWrite down your answer, but do not explain it. Input: `abc`\",\n",
       " 'output': \" Thank you for the input and for confirming the output of each letter I printed. I simply followed the instructions to repeat the given string 'abc' by printing each letter one at a time without any additional explanations. Please let me know if you need me to repeat this process for a different input string.\",\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'a'}, log=\"\\nInvoking type_letter: {'letter': 'a'}\\n\\t\", message_log=[AIMessage(content='<tool>{\\n    \"tool_name\": \"type_letter\",\\n    \"arguments\": {\\n        \"letter\": \"a\"\\n    }\\n}</tool>\\n')]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'b'}, log=\"\\nInvoking type_letter: {'letter': 'b'}\\n\\t\", message_log=[AIMessage(content='<tool>{\\n    \"tool_name\": \"type_letter\", \\n    \"arguments\": {\\n        \"letter\": \"b\"\\n    }\\n}</tool>\\n')]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='type_letter', tool_input={'letter': 'c'}, log=\"\\nInvoking type_letter: {'letter': 'c'}\\n\\t\", message_log=[AIMessage(content='<tool>{\\n    \"tool_name\": \"type_letter\",\\n    \"arguments\": {\\n        \"letter\": \"c\"\\n    }\\n}</tool>\\n')]),\n",
       "   'OK')],\n",
       " 'state': 'abc'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Typewriter (1 tool)\"]\n",
    "agent_factory = CustomAgentFactory(task, \"claude-2.1\")\n",
    "\n",
    "agent_factory().invoke({\"question\": \"abc\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b32e7d-3986-4461-8a3b-8e9b6d4008cb",
   "metadata": {},
   "source": [
    "Define the test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a165f3a1-4e70-4caa-b082-78d4e0c56410",
   "metadata": {},
   "source": [
    "Let's make an experiment id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066d7695-416c-4faf-8c33-c40e5f136672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_uuid = \"3f3e\"  # Or generate ranom using uuid.uuid4().hex[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d390b6-9ade-424c-aabb-d450f52ed121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests = [\n",
    "    # 2-tuple of (architecture, model name)\n",
    "    (\"custom_agent\", \"mixtral-8x7b-instruct-fw\"),\n",
    "    (\"custom_agent\", \"claude-2.1\"),\n",
    "    (\"custom_agent\", \"claude-2\"),\n",
    "    (\"custom_agent\", \"yi-34b-200k-fw\"),\n",
    "    (\"custom_agent\", \"llama-v2-70b-chat-fw\"),\n",
    "    (\"custom_agent\", \"llama-v2-13b-chat-fw\"),\n",
    "    (\"openai_functions\", \"gpt-3.5-turbo-1106\"),\n",
    "    (\"openai_functions\", \"gpt-3.5-turbo-0613\"),\n",
    "    (\"openai_functions\", \"gpt-4-1106-preview\"),\n",
    "    (\"openai_functions\", \"gpt-4-0613\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b7c24-8b4d-4bd7-8b00-365fbe61897f",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6fbc3ef-7a3f-430f-8b79-45af5861b3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Tool Usage - Typewriter (1 tool) already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/82ca6840-cf23-4bb0-a9be-55237ebbe9d3.\n",
      "\n",
      "Benchmarking Tool Usage - Typewriter (1 tool) with model: gpt-3.5-turbo-1106 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-1106-Tool Usage - Typewriter (1 tool)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/ae274b6a-d1e3-4ef4-873b-888fb66fe003?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/82ca6840-cf23-4bb0-a9be-55237ebbe9d3\n",
      "[------------------------------------------------->] 20/20\n",
      "Benchmarking Tool Usage - Typewriter (1 tool) with model: gpt-3.5-turbo-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-0613-Tool Usage - Typewriter (1 tool)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/41ab8a52-4a73-4b52-952e-3a7d46468797?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/82ca6840-cf23-4bb0-a9be-55237ebbe9d3\n",
      "[------------------------------------------------->] 20/20\n",
      "Benchmarking Tool Usage - Typewriter (1 tool) with model: gpt-4-1106-preview and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-1106-preview-Tool Usage - Typewriter (1 tool)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/7710c6e8-0e6f-4352-b21b-e5831c164fd0?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/82ca6840-cf23-4bb0-a9be-55237ebbe9d3\n",
      "[------------------------------------------------->] 20/20\n",
      "Benchmarking Tool Usage - Typewriter (1 tool) with model: gpt-4-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-0613-Tool Usage - Typewriter (1 tool)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/3ec20642-5ec2-4686-867f-f28bcd4a3d72?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (1 tool) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/82ca6840-cf23-4bb0-a9be-55237ebbe9d3\n",
      "[------------------------------------------------->] 20/20Dataset Tool Usage - Typewriter (26 tools) already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/2f462c7a-f9b9-46e7-b96b-7469e965f478.\n",
      "\n",
      "Benchmarking Tool Usage - Typewriter (26 tools) with model: gpt-3.5-turbo-1106 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-1106-Tool Usage - Typewriter (26 tools)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/f5fadf66-6d02-41c8-bd95-e1100fcbfafa?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (26 tools) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/2f462c7a-f9b9-46e7-b96b-7469e965f478\n",
      "[>                                                 ] 0/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example c4af9bd6-84c5-4b25-ac0a-04c307fc7441 with inputs {'question': 'information'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 17fb72e265f1b0b1f24060ad09aa56e5 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------->                                      ] 5/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 0e6b2b64-57b1-4e8a-8611-4edab1cea326 with inputs {'question': 'school'}\n",
      "Error Type: RuntimeError, Message: generator raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------->                                   ] 6/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example ff31e6be-4d37-4c29-b869-9b3a2075ff25 with inputs {'question': 'computer'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID ad2bc2cc85acf13dd40aaf90d77a2e0c in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------->                                ] 7/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 80264d75-4aa4-484a-bbdc-4f82f930a69d with inputs {'question': 'student'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID bce5cb60e964c615c03ae37b284390a0 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------->                              ] 8/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 8af5bd36-fc11-4b23-9019-f642cfaf8a01 with inputs {'question': 'horse'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 6836043ac2fce7a5b8748e01895a1a32 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------->                      ] 11/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example de38ad8a-ca82-44d6-a4ba-ff3bd5a6640e with inputs {'question': 'cat'}\n",
      "Error Type: RuntimeError, Message: generator raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------->                    ] 12/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 607d5f26-c165-4034-b5f9-0f592913cb71 with inputs {'question': 'dog'}\n",
      "Error Type: RuntimeError, Message: generator raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------------------------->               ] 14/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example c1a0336d-ae2f-4cf3-a204-58eec17330e7 with inputs {'question': 'house'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID ad6024af7b61d6309987d3994f8839ae in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 20/20\n",
      "Benchmarking Tool Usage - Typewriter (26 tools) with model: gpt-3.5-turbo-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-0613-Tool Usage - Typewriter (26 tools)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/6860edf5-fc08-4e24-bd7c-9cfb53cbb18d?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (26 tools) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/2f462c7a-f9b9-46e7-b96b-7469e965f478\n",
      "[>                                                 ] 0/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 2d4e99fc-8495-468e-8429-6c25a2d176f3 with inputs {'question': 'keyboard'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4c72ba8494a00bb7e98881ee6901c9cb in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------->                                      ] 5/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 0e6b2b64-57b1-4e8a-8611-4edab1cea326 with inputs {'question': 'school'}\n",
      "Error Type: BadRequestError, Message: Error code: 400 - {'error': {'message': \"'s()' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'messages.2.function_call.name'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------->                                   ] 6/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 8af5bd36-fc11-4b23-9019-f642cfaf8a01 with inputs {'question': 'horse'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 576744404b64d81872441e295412fc28 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 20/20\n",
      "Benchmarking Tool Usage - Typewriter (26 tools) with model: gpt-4-1106-preview and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-1106-preview-Tool Usage - Typewriter (26 tools)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/c12566e8-c6a4-4c8d-88f4-b026f03c787b?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (26 tools) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/2f462c7a-f9b9-46e7-b96b-7469e965f478\n",
      "[------------------------------------------------->] 20/20\n",
      "Benchmarking Tool Usage - Typewriter (26 tools) with model: gpt-4-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-0613-Tool Usage - Typewriter (26 tools)-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/0980e35d-c630-4be3-a67d-d7fafc872e3f?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Typewriter (26 tools) at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/2f462c7a-f9b9-46e7-b96b-7469e965f478\n",
      "[------->                                          ] 3/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example e5bc36cc-e077-4a6f-80a0-9ce1794a77e5 with inputs {'question': 'communication'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 87e0fa2a4f67038c758f2a48c4103836 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------->                                        ] 4/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 2d4e99fc-8495-468e-8429-6c25a2d176f3 with inputs {'question': 'keyboard'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8b838371871961de094710e4507cbe9c in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------->                                ] 7/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example ff31e6be-4d37-4c29-b869-9b3a2075ff25 with inputs {'question': 'computer'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID e9517e6051dd41e312a14b77fe587df7 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------->                              ] 8/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 23649150-3c39-4beb-ba5d-c50ff1c66c63 with inputs {'question': 'church'}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID ff5617c09a4f8e1d0e19889b76ad4cd7 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 20/20Dataset Tool Usage - Relational Data already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/df6be6c9-05b3-445e-8836-ebb4aba63826.\n",
      "\n",
      "Benchmarking Tool Usage - Relational Data with model: gpt-3.5-turbo-1106 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-1106-Tool Usage - Relational Data-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/9c057691-1109-403c-8118-f5e84a0be76b?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Relational Data at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/df6be6c9-05b3-445e-8836-ebb4aba63826\n",
      "[------------------------------------------------->] 21/21\n",
      "Benchmarking Tool Usage - Relational Data with model: gpt-3.5-turbo-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-0613-Tool Usage - Relational Data-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/1a039def-7bf9-4a6e-8408-1c0470bdcc11?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Relational Data at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/df6be6c9-05b3-445e-8836-ebb4aba63826\n",
      "[------------------------------------------------->] 21/21\n",
      "Benchmarking Tool Usage - Relational Data with model: gpt-4-1106-preview and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-1106-preview-Tool Usage - Relational Data-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/3409a746-83a4-4157-9da0-0ad6f010df79?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Relational Data at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/df6be6c9-05b3-445e-8836-ebb4aba63826\n",
      "[------------------------------------------------->] 21/21\n",
      "Benchmarking Tool Usage - Relational Data with model: gpt-4-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-0613-Tool Usage - Relational Data-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/6a0f050a-6724-4ada-9b8b-367436ce5d66?eval=true\n",
      "\n",
      "View all tests for Dataset Tool Usage - Relational Data at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/df6be6c9-05b3-445e-8836-ebb4aba63826\n",
      "[------------------------------------------------->] 21/21Dataset Multiverse Math already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/108bdc68-1808-4b60-92ef-fbd9bd7e1ad0.\n",
      "\n",
      "Benchmarking Multiverse Math with model: gpt-3.5-turbo-1106 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-1106-Multiverse Math-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/df2cb0fa-1675-4004-9fd8-c276c86471db?eval=true\n",
      "\n",
      "View all tests for Dataset Multiverse Math at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/108bdc68-1808-4b60-92ef-fbd9bd7e1ad0\n",
      "[------------------------------------------------->] 10/10\n",
      "Benchmarking Multiverse Math with model: gpt-3.5-turbo-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-3.5-turbo-0613-Multiverse Math-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/f8ec06e2-8c89-4324-8e02-9d8c3aca88d3?eval=true\n",
      "\n",
      "View all tests for Dataset Multiverse Math at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/108bdc68-1808-4b60-92ef-fbd9bd7e1ad0\n",
      "[------------------------------------------------->] 10/10\n",
      "Benchmarking Multiverse Math with model: gpt-4-1106-preview and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-1106-preview-Multiverse Math-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/f499a8c9-86b8-4292-8973-0ca509592eac?eval=true\n",
      "\n",
      "View all tests for Dataset Multiverse Math at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/108bdc68-1808-4b60-92ef-fbd9bd7e1ad0\n",
      "[>                                                 ] 0/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 4ac33c1a-62f0-4da4-9455-07b582f6ff52 with inputs {'question': 'calculate 101 to the power of 0.5 to 4 digits of precision'}\n",
      "Error Type: BadRequestError, Message: Error code: 400 - {'error': {'message': '\\'\"{\\\\\\\\\"a\\\\\\\\\":101,\\\\\\\\\"b\\\\\\\\\":0.5}\"\\' does not match \\'^[a-zA-Z0-9_-]{1,64}$\\' - \\'messages.2.function_call.name\\'', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 10/10\n",
      "Benchmarking Multiverse Math with model: gpt-4-0613 and arch: openai_functions\n",
      "View the evaluation results for project 'gpt-4-0613-Multiverse Math-2023-12-14-3f3e' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/6b2036f7-0606-4eff-92ae-49262cea09b9?eval=true\n",
      "\n",
      "View all tests for Dataset Multiverse Math at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/108bdc68-1808-4b60-92ef-fbd9bd7e1ad0\n",
      "[------------------------------------------------->] 10/10"
     ]
    }
   ],
   "source": [
    "client = Client()  # Launch langsmith client for cloning datasets\n",
    "today = datetime.date.today().isoformat()\n",
    "rate_limiter = RateLimiter(requests_per_second=2)\n",
    "\n",
    "for task in registry:\n",
    "    if task.type != \"ToolUsageTask\":\n",
    "        continue\n",
    "\n",
    "    dataset_name = task.name\n",
    "    clone_public_dataset(task.dataset_id, dataset_name=dataset_name)\n",
    "\n",
    "    for arch, model in tests:\n",
    "        print()\n",
    "        print(f\"Benchmarking {task.name} with model: {model} and arch: {arch}\")\n",
    "        eval_config = task.get_eval_config()\n",
    "\n",
    "        if arch == \"openai_functions\":\n",
    "            agent_factory = OpenAIAgentFactory(\n",
    "                task, model=model, rate_limiter=rate_limiter\n",
    "            )\n",
    "        elif arch == \"custom_agent\":\n",
    "            agent_factory = CustomAgentFactory(\n",
    "                task, model=model, rate_limiter=rate_limiter\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        client.run_on_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            llm_or_chain_factory=agent_factory,\n",
    "            evaluation=eval_config,\n",
    "            verbose=False,\n",
    "            project_name=f\"{model}-{task.name}-{today}-{experiment_uuid}\",\n",
    "            tags=[model],\n",
    "            concurrency_level=5,\n",
    "            project_metadata={\n",
    "                \"model\": model,\n",
    "                \"id\": experiment_uuid,\n",
    "                \"task\": task.name,\n",
    "                \"date\": today,\n",
    "                \"langchain_benchmarks_version\": __version__,\n",
    "                \"arch\": arch,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7999f-e8ab-45a6-88a9-0ae76f3d24cf",
   "metadata": {},
   "source": [
    "## Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7818572a-a5fb-4153-bbe0-6f9e90813a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langsmith.client import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7890951-ffde-4706-95e5-ae3e9bf0e8a6",
   "metadata": {},
   "source": [
    "Let's fetch all the data that has the same experiment ID and place it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44822aa4-8c4e-46be-8126-b79a9acdf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = [\"3f3e\"]\n",
    "\n",
    "\n",
    "def _endswith(s, suffixes):\n",
    "    return any(s.endswith(suffix) for suffix in suffixes)\n",
    "\n",
    "\n",
    "client = Client()\n",
    "projects = [\n",
    "    project\n",
    "    for project in client.list_projects()\n",
    "    if _endswith(project.name, experiment_ids)\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for project in projects:\n",
    "    # Temporary way to get tag information\n",
    "    project_info = client.read_project(project_id=project.id)\n",
    "    try:\n",
    "        test_results = client.get_test_results(project_name=project.name)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    for k, v in project_info.extra[\"metadata\"].items():\n",
    "        test_results[k] = v\n",
    "\n",
    "    dfs.append(test_results)\n",
    "\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065b7a0-d514-49f7-9d79-67181c41f56d",
   "metadata": {},
   "source": [
    "Compute a standardized \"correct\" column. It uses \"Correct Final State\" for tool usage tasks, and \"correctness (which is based on output) for the other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c0466a-25f4-44d7-bd2a-20da51461994",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "\n",
    "for r in df.to_dict(orient=\"records\"):\n",
    "    if \"Typewriter\" in r[\"task\"]:\n",
    "        correct.append(r[\"feedback.Correct Final State\"])\n",
    "    else:\n",
    "        correct.append(r[\"feedback.correctness\"])\n",
    "\n",
    "df[\"correct\"] = correct\n",
    "df[\"correct\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b8ae9-c84b-4ebc-88ab-fa0ac5e28a57",
   "metadata": {},
   "source": [
    "Compute some statistics. We're using estimating standard error of the mean assuming a bernoulli process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59d080c-d3ac-43c3-a527-9961913db2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = df.groupby([\"model\", \"task\"])[\"correct\"].sum().to_frame(\"num_correct\")\n",
    "total = df.groupby([\"task\", \"model\"]).size().to_frame(\"total\")\n",
    "stats_df = total.join(num_correct)\n",
    "stats_df[\"% correct\"] = stats_df[\"num_correct\"] / stats_df[\"total\"]\n",
    "stats_df[\"error\"] = np.sqrt(\n",
    "    stats_df[\"% correct\"] * (1 - stats_df[\"% correct\"]) / stats_df[\"total\"]\n",
    ")\n",
    "\n",
    "# stats_df\n",
    "\n",
    "models = [\n",
    "    \"llama-v2-70b-chat-fw\",\n",
    "    \"mixtral-8x7b-instruct-fw\",\n",
    "    \"claude-2\",\n",
    "    \"claude-2.1\",\n",
    "    \"gpt-3.5-turbo-0613\",\n",
    "    \"gpt-3.5-turbo-1106\",\n",
    "    \"gpt-4-0613\",\n",
    "    \"gpt-4-1106-preview\",\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"Tool Usage - Typewriter (1 tool)\",\n",
    "    \"Tool Usage - Typewriter (26 tools)\",\n",
    "    \"Multiverse Math\",\n",
    "    \"Tool Usage - Relational Data\",\n",
    "]\n",
    "\n",
    "stats_df = stats_df.reset_index()\n",
    "stats_df = stats_df[stats_df[\"model\"].isin(models)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f79af-128c-4e2e-8c1e-807e397b9791",
   "metadata": {
    "tags": []
   },
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df66a1-960c-40a3-abc8-58b503fceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(tasks))  # the label locations\n",
    "width = 0.08  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\", figsize=(16, 4))\n",
    "colormap = plt.get_cmap(\"Set2\").colors\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    try:\n",
    "        results = stats_df.set_index(\"model\").loc[model]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    color = colormap[idx]\n",
    "\n",
    "    results = results.set_index(\"task\").loc[tasks]\n",
    "    measurement = results[\"% correct\"]\n",
    "\n",
    "    values = [round(m, 2) for m in measurement]\n",
    "\n",
    "    offset = width * multiplier * 1.4\n",
    "    rects = ax.bar(\n",
    "        x + offset, values, width, label=model, yerr=results[\"error\"], color=color\n",
    "    )\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel(\"% Questions Answered Correctly\")\n",
    "ax.set_title(\"Tool Usage Performance\")\n",
    "ax.set_xticks(x + width + 0.3, tasks)\n",
    "ax.legend(\n",
    "    loc=\"center left\", ncols=1, bbox_to_anchor=(1.0, 0.5), frameon=False, title=\"Model\"\n",
    ")\n",
    "ax.set_ylim(0, 1.10)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
