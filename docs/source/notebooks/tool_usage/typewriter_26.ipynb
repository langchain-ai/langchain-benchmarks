{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e64bc9-bdf7-4fe5-9839-5d160c425c61",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Typewriter: 26 Tools\n",
    "\n",
    "This is a variation of the typewriter task in which the agent has access to 26 parameterless tools.\n",
    "\n",
    "Each tool represents a letter of the alphabet (e.g., 'a', 'b', 'c').\n",
    "\n",
    "The agent can use each tool to \"print\" the corresponding letter on a piece of virtual paper.\n",
    "\n",
    "The objective for the agent is to \"print\" the user's input on the paper exactly.\n",
    "\n",
    "---------\n",
    "\n",
    "For this code to work, please configure LangSmith environment variables with your credentials.\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"sk-...\"  # Your api key.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aef2b32-a5df-421f-8be3-a2ef27372ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Tool Usage - Typewriter (26 tools)                                                                                                                         </td></tr>\n",
       "<tr><td>Type       </td><td>ToolUsageTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID </td><td><a href=\"https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d\" target=\"_blank\" rel=\"noopener\">128af05e-aa00-4e3b-a958-d166dd450581</a></td></tr>\n",
       "<tr><td>Description</td><td>Environment with 26 tools each tool represents a letter of the alphabet.\n",
       "\n",
       "The objective of this task is to evaluate the model's ability the use tools\n",
       "for a simple repetition task.\n",
       "\n",
       "For example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\n",
       "\n",
       "The dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\n",
       "\n",
       "This is a variation of the typer writer task, where 26 parameterless tools are\n",
       "given instead of a single tool that takes a letter as an argument.                                                                                                                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ToolUsageTask(name='Tool Usage - Typewriter (26 tools)', dataset_id='https://smith.langchain.com/public/128af05e-aa00-4e3b-a958-d166dd450581/d', description=\"Environment with 26 tools each tool represents a letter of the alphabet.\\n\\nThe objective of this task is to evaluate the model's ability the use tools\\nfor a simple repetition task.\\n\\nFor example, if the string is 'abc', the tools 'a', 'b', and 'c' must be invoked in that order.\\n\\nThe dataset includes examples of varying difficulty. The difficulty is measured by the length of the string.\\n\\nThis is a variation of the typer writer task, where 26 parameterless tools are\\ngiven instead of a single tool that takes a letter as an argument.\\n\", create_environment=<function get_environment at 0x7f6cd20e4f40>, instructions=\"Repeat the given string by using the provided tools. Do not write anything else or provide any explanations. For example, if the string is 'abc', you must invoke the tools 'a', 'b', and 'c' in that order. Please invoke the functions without any arguments.\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = registry[\"Tool Usage - Typewriter (26 tools)\"]\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33a639-3caf-4314-8ea7-1c7c8b1d114d",
   "metadata": {},
   "source": [
    "Clone the dataset associaetd with this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Tool Usage - Typewriter (26 tools) already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/2f462c7a-f9b9-46e7-b96b-7469e965f478.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(task.dataset_id, dataset_name=task.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462f7b8-fd42-4613-ab5f-5f3cbbc37d28",
   "metadata": {},
   "source": [
    "Let's build an agent that we can use for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce51f81-1b3a-4dda-a382-c2fed3013af1",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "The environment consists of 26 tools and a virtual paper.\n",
    "\n",
    "Each tool is responsible for printing a letter on the paper that corresponds to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61535a75-24f6-4727-9549-f76c263e9153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = task.create_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35a0a1d-5a1e-4de1-8d8c-c7c9a264a6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='a', description='a() -> str - Run to Type the letter \"a\".', args_schema=<class 'pydantic.v1.main.aSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f6cd20e6520>),\n",
       " StructuredTool(name='b', description='b() -> str - Run to Type the letter \"b\".', args_schema=<class 'pydantic.v1.main.bSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f6cd20e65c0>),\n",
       " StructuredTool(name='c', description='c() -> str - Run to Type the letter \"c\".', args_schema=<class 'pydantic.v1.main.cSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f6cd20e6660>),\n",
       " StructuredTool(name='d', description='d() -> str - Run to Type the letter \"d\".', args_schema=<class 'pydantic.v1.main.dSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f6cd20e6700>),\n",
       " StructuredTool(name='e', description='e() -> str - Run to Type the letter \"e\".', args_schema=<class 'pydantic.v1.main.eSchemaSchema'>, func=<function _create_typing_func.<locals>.func at 0x7f6cd20e67a0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bea0190-39ec-4f30-9a00-90136bc6bf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools[0].invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7444da-15a1-455a-b22e-639cbfff8432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tools[3].invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12bd710-5c01-4539-a4b9-afbf03164923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.read_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d62a13-3771-460f-b131-4443f669ca3d",
   "metadata": {},
   "source": [
    "## Agent Factory\n",
    "\n",
    "For evaluation, we need an agent factory that will create a new instance of an agent executor for every evaluation run.\n",
    "\n",
    "We'll use an `OpenAIAgentFactory` provided with LangChain Benchmarks -- look at the `intro` section to see how to define your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6142cf4e-862c-47a3-aa75-81d7d3231308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hello',\n",
       " 'output': 'hello\\nhello',\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='h', tool_input={}, log='\\nInvoking: `h` with `{}`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'h', 'arguments': ''}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='e', tool_input={}, log='\\nInvoking: `e` with `{}`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'e', 'arguments': ''}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='l', tool_input={}, log='\\nInvoking: `l` with `{}`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'l', 'arguments': ''}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='l', tool_input={}, log='\\nInvoking: `l` with `{}`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'l', 'arguments': ''}})]),\n",
       "   'OK'),\n",
       "  (AgentActionMessageLog(tool='o', tool_input={}, log='\\nInvoking: `o` with `{}`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'o', 'arguments': ''}})]),\n",
       "   'OK')],\n",
       " 'state': 'hello'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_benchmarks.tool_usage import agents\n",
    "\n",
    "agent_factory = agents.OpenAIAgentFactory(task, model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "# Let's test that our agent works\n",
    "agent = agent_factory()\n",
    "agent.invoke({\"question\": \"hello\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "## Eval\n",
    "\n",
    "Let's evaluate an agent now.\n",
    "\n",
    "Eval code below has not been run yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32763c-79ab-426a-8fc6-bf8ebb0dd432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.tool_usage import get_eval_config\n",
    "\n",
    "experiment_uuid = uuid.uuid4().hex[:4]\n",
    "\n",
    "client = Client()\n",
    "\n",
    "models = [\"gpt-3.5-turbo-16k\"]\n",
    "\n",
    "for model in models:\n",
    "    print()\n",
    "    # The eval config will evaluate the state, but not the output which is meaningless for this task.\n",
    "    eval_config = get_eval_config(output_evaluation=\"none\")\n",
    "    agent_factory = agents.OpenAIAgentFactory(task, model=model)\n",
    "    test_run = client.run_on_dataset(\n",
    "        dataset_name=task.name,\n",
    "        llm_or_chain_factory=agent_factory,\n",
    "        evaluation=eval_config,\n",
    "        verbose=False,\n",
    "        concurrency_level=1,\n",
    "        project_name=f\"typewriter-26-{model}-{experiment_uuid}\",\n",
    "        tags=[model],\n",
    "        project_metadata={\n",
    "            \"model\": model,\n",
    "            \"arch\": \"openai-functions-agent\",\n",
    "            \"id\": experiment_uuid,\n",
    "        },\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
