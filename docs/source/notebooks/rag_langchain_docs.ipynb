{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# Q&A over LangChain Docs\n",
    "\n",
    "Let's evaluate your architecture on a Q&A dataset for the LangChain python docs. For more examples of how to test different embeddings, indexing strategies, and architectures, see the [Evaluating RAG Architectures on Benchmark Tasks](rag_evaluations.ipynb) notebook.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "We will install quite a few prerequisites for this example since we are comparing many techniques and models.\n",
    "\n",
    "We will be using LangSmith to capture the evaluation traces. You can make a free account at [smith.langchain.com](https://smith.langchain.com/). Once you've done so, you can make an API key and set it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8397dde8-cfde-4f98-b331-e6dab0618f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44b59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -U --quiet langchain langsmith langchainhub langchain_benchmarks\n",
    "# %pip install --quiet chromadb openai huggingface pandas langchain_experimental sentence_transformers pyarrow anthropic tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae13f6-cd40-41e6-bd02-bd683e91cbff",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"sk-...\"  # Your API key\n",
    "\n",
    "# # Silence warnings from HuggingFace\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
   "metadata": {},
   "source": [
    "## Review Q&A Tasks\n",
    "\n",
    "The registry provides configurations to test out common architectures on curated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                    </th><th>Type         </th><th>Dataset ID                          </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LangChain Docs Q&amp;A      </td><td>RetrievalTask</td><td>452ccafc-18e1-4314-885b-edd735f17b9d</td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model&#x27;s response relative to the retrieved documents (if any).              </td></tr>\n",
       "<tr><td>Semi-structured Earnings</td><td>RetrievalTask</td><td>c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</td><td>Questions and answers based on PDFs containing tables and charts.\n",
       "\n",
       "The task provides the raw documents as well as factory methods to easily index them\n",
       "and create a retriever.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model&#x27;s response relative to the retrieved documents (if any).              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[RetrievalTask(name='LangChain Docs Q&A', dataset_id='452ccafc-18e1-4314-885b-edd735f17b9d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x126948e00>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x126948ea0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x126948f40>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x12600e0c0>}, get_docs=<function load_cached_docs at 0x102d17240>), RetrievalTask(name='Semi-structured Earnings', dataset_id='c47d9617-ab99-4d6e-a6e6-92b8daf85a7d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x1269496c0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x126949760>, 'hyde': <function _chroma_hyde_retriever_factory at 0x126949800>}, architecture_factories={}, get_docs=<function load_docs at 0x126949620>)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry = registry.filter(Type=\"RetrievalTask\")\n",
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671282f8-c455-4390-b018-e53bbd833093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name                  </td><td>LangChain Docs Q&amp;A                        </td></tr>\n",
       "<tr><td>Type                  </td><td>RetrievalTask                             </td></tr>\n",
       "<tr><td>Dataset ID            </td><td>452ccafc-18e1-4314-885b-edd735f17b9d      </td></tr>\n",
       "<tr><td>Description           </td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model&#x27;s response relative to the retrieved documents (if any).                                           </td></tr>\n",
       "<tr><td>Retriever Factories   </td><td>basic, parent-doc, hyde                   </td></tr>\n",
       "<tr><td>Architecture Factories</td><td>conversational-retrieval-qa               </td></tr>\n",
       "<tr><td>get_docs              </td><td>&lt;function load_cached_docs at 0x102d17240&gt;</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "RetrievalTask(name='LangChain Docs Q&A', dataset_id='452ccafc-18e1-4314-885b-edd735f17b9d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x126948e00>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x126948ea0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x126948f40>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x12600e0c0>}, get_docs=<function load_cached_docs at 0x102d17240>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_docs = registry[\"LangChain Docs Q&A\"]\n",
    "langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LangChain Docs Q&A already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/3f29798f-5939-4643-bd99-008ca66b72ed.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58247f5-b9bd-4cc5-9632-78bc21bb10b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c698bb93d4548fcacbb3c08990642c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
    "\n",
    "docs = langchain_docs.get_docs()\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "# Indexes the documents with the specified embeddings\n",
    "# Note that this does not apply any chunking to the docs,\n",
    "# which means the documents can be of arbitrary length\n",
    "retriever = retriever_factory(embeddings, docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41e64350-63a7-4e7d-8e03-7dc459c444cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def format_docs(docs: Sequence[Document]) -> str:\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_string = (\n",
    "            f\"<document index='{i}'>\\n\"\n",
    "            f\"<source>{doc.metadata.get('source')}</source>\\n\"\n",
    "               f\"<doc_content>{doc.page_content}</doc_content>\\n\"\n",
    "            \"</document>\"\n",
    "        )\n",
    "        formatted_docs.append(doc_string)\n",
    "    formatted_str = \"\\n\".join(formatted_docs)\n",
    "    return f\"<documents>\\n{formatted_str}\\n</documents>\"\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an AI assistant answering questions about LangChain.\"\n",
    "        \"\\n{context}\\n\"\n",
    "        \"Respond solely based on the document content.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatAnthropic(model=\"claude-2.1\", temperature=1)\n",
    "\n",
    "response_generator = (prompt | llm | StrOutputParser()).with_config(\n",
    "    run_name=\"GenerateResponse\",\n",
    ")\n",
    "chain = (\n",
    "        RunnableAssign(\n",
    "            {\n",
    "                \"context\": (\n",
    "                    itemgetter(\"question\") | retriever | format_docs\n",
    "                ).with_config(run_name=\"FormatDocs\")\n",
    "            }\n",
    "        )\n",
    "        | response_generator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10a1fca9-d356-4cff-93a9-c4f63944e57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the LangChain documentation, the LangChain Expression Language (LCEL) is a declarative way to easily compose chains together. Key things to know about LCEL:\\n\\n- It was designed to support putting prototypes into production with no code changes, from simple \"prompt + LLM\" chains to complex chains with hundreds of steps. \\n\\n- It provides streaming support - when you build chains with LCEL you get the best possible time-to-first-token, streaming tokens from the LLM to output parsers incrementally.\\n\\n- Chains built with LCEL can be called synchronously (like in a notebook) or asynchronously (like in a production server), using the same code.\\n\\n- LCEL automatically runs steps in parallel when possible, minimizing latency. \\n\\n- It supports configuring retries and fallbacks to make chains more reliable.\\n\\n- You can access intermediate chain results before the final output is ready, which helps with debugging and user notifications.\\n\\n- LCEL chains get input and output validation schemas automatically.\\n\\n- All steps are logged to LangSmith for observability.\\n\\n- Chains authored in LCEL can be easily deployed with LangServe.\\n\\nSo in summary, the LangChain Expression Language is'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What's expression language?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Let's evaluate your RAG architecture on the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "513042fe-2878-44f8-ae84-05b9d521c1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith.client import Client\n",
    "from langchain_benchmarks.rag import get_eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-essential-pot-37' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/d57047ac-d6e7-49c2-bd52-e2158e2ce56f?eval=true\n",
      "\n",
      "View all tests for Dataset LangChain Docs Q&A at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/3f29798f-5939-4643-bd99-008ca66b72ed\n",
      "[>                                                 ] 1/86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 86/86\n",
      " Eval quantiles:\n",
      "                               0.25      0.5      0.75      mean      mode\n",
      "embedding_cosine_distance  0.086465  0.12291  0.159078  0.128270  0.046088\n",
      "score_string:accuracy      0.500000  0.70000  1.000000  0.641860  0.700000\n",
      "faithfulness               0.700000  1.00000  1.000000  0.860465  1.000000\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "RAG_EVALUATION = get_eval_config()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86578d5-be5c-4bcd-9dcb-35280eeed3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01811b97-cb28-42a6-920a-7a700f77f19d",
   "metadata": {},
   "source": [
    "## Evaluate with a default factory\n",
    "\n",
    "The task can define default chain and retriever \"factories\", whic provide a default architecture that you can modify by choosing the llms, prompts, etc. Let's try the `conversational-retrieval-qa` factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d2e139-2653-4f7b-944b-91ef52f43d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Factory for creating a conversational retrieval QA chain\n",
    "chain_factory = langchain_docs.architecture_factories[\"conversational-retrieval-qa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e938e5b-c430-4ab1-ab7d-84c33f83bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9be718-64f0-4706-9527-240a1cdb3ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' <b>\\n\\n- Expression language (LCEL) is a declarative way to easily compose chains together in LangChain. It was designed to support putting prototypes into production with no code changes, from simple \"prompt + LLM\" chains to complex chains with hundreds of steps [0].\\n\\n- Key features of LCEL include streaming support, asynchronous support, optimized parallel execution, configurable retries and fallbacks, access to intermediate results, input/output validation schemas, seamless integration with LangSmith tracing and LangServe deployment [0].\\n\\n- The LangChain cookbook contains examples of common tasks using LCEL like chaining prompts and LLMs, adding retrieval, querying databases, writing code, adding memory and moderation, etc [1].\\n\\n</b>\\n\\n[0] - https://langchain.org/docs/expression_language\\n[1] - https://langchain.org/docs/expression_language/cookbook'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "\n",
    "# Example\n",
    "llm = ChatAnthropic(model=\"claude-2\", temperature=1)\n",
    "\n",
    "\n",
    "chain = chain_factory(retriever, llm=llm)\n",
    "\n",
    "chain.invoke({\"question\": \"What is expression language?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9c013e2-241a-4def-9aa6-ccb34273eeb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=partial(chain_factory, retriever=retriever, llm=llm),\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
