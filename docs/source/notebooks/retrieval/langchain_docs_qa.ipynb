{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# Q&A over LangChain Docs\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/retrieval/langchain_docs_qa.ipynb)\n",
    "\n",
    "Let's evaluate your architecture on a Q&A dataset for the LangChain python docs. For more examples of how to test different embeddings, indexing strategies, and architectures, see the [Evaluating RAG Architectures on Benchmark Tasks](./comparing_techniques.ipynb) notebook.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "We will install quite a few prerequisites for this example since we are comparing many techniques and models.\n",
    "\n",
    "We will be using LangSmith to capture the evaluation traces. You can make a free account at [smith.langchain.com](https://smith.langchain.com/). Once you've done so, you can make an API key and set it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44b59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet langchain langsmith langchainhub langchain_benchmarks\n",
    "%pip install --quiet chromadb openai huggingface pandas langchain_experimental sentence_transformers pyarrow anthropic tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae13f6-cd40-41e6-bd02-bd683e91cbff",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls_...\"  # Your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these with your own API keys\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "# Silence warnings from HuggingFace\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
   "metadata": {},
   "source": [
    "## Review Q&A Tasks\n",
    "\n",
    "The registry provides configurations to test out common architectures on curated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry = registry.filter(Type=\"RetrievalTask\")\n",
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671282f8-c455-4390-b018-e53bbd833093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain_docs = registry[\"LangChain Docs Q&A\"]\n",
    "langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58247f5-b9bd-4cc5-9632-78bc21bb10b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"thenlper/gte-base\",\n",
    "    model_kwargs={\"device\": 0},  # Comment out to use CPU\n",
    ")\n",
    "\n",
    "docs = langchain_docs.get_docs()\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "# Indexes the documents with the specified embeddings\n",
    "# Note that this does not apply any chunking to the docs,\n",
    "# which means the documents can be of arbitrary length\n",
    "retriever = retriever_factory(embeddings, docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e64350-63a7-4e7d-8e03-7dc459c444cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "\n",
    "\n",
    "def format_docs(docs: Sequence[Document]) -> str:\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_string = (\n",
    "            f\"<document index='{i}'>\\n\"\n",
    "            f\"<source>{doc.metadata.get('source')}</source>\\n\"\n",
    "            f\"<doc_content>{doc.page_content}</doc_content>\\n\"\n",
    "            \"</document>\"\n",
    "        )\n",
    "        formatted_docs.append(doc_string)\n",
    "    formatted_str = \"\\n\".join(formatted_docs)\n",
    "    return f\"<documents>\\n{formatted_str}\\n</documents>\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant answering questions about LangChain.\"\n",
    "            \"\\n{context}\\n\"\n",
    "            \"Respond solely based on the document content.\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatAnthropic(model=\"claude-2.1\", temperature=1)\n",
    "\n",
    "response_generator = (prompt | llm | StrOutputParser()).with_config(\n",
    "    run_name=\"GenerateResponse\",\n",
    ")\n",
    "chain = (\n",
    "    RunnableAssign(\n",
    "        {\n",
    "            \"context\": (itemgetter(\"question\") | retriever | format_docs).with_config(\n",
    "                run_name=\"FormatDocs\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    | response_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1fca9-d356-4cff-93a9-c4f63944e57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"What's expression language?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Let's evaluate your RAG architecture on the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513042fe-2878-44f8-ae84-05b9d521c1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.rag import get_eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client()\n",
    "RAG_EVALUATION = get_eval_config()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86578d5-be5c-4bcd-9dcb-35280eeed3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01811b97-cb28-42a6-920a-7a700f77f19d",
   "metadata": {},
   "source": [
    "## Evaluate with a default factory\n",
    "\n",
    "The task can define default chain and retriever \"factories\", which provide a default architecture that you can modify by choosing the llms, prompts, etc. Let's try the `conversational-retrieval-qa` factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2e139-2653-4f7b-944b-91ef52f43d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Factory for creating a conversational retrieval QA chain\n",
    "chain_factory = langchain_docs.architecture_factories[\"conversational-retrieval-qa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9be718-64f0-4706-9527-240a1cdb3ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "\n",
    "# Example\n",
    "llm = ChatAnthropic(model=\"claude-2\", temperature=1)\n",
    "\n",
    "\n",
    "chain = chain_factory(retriever, llm=llm)\n",
    "\n",
    "chain.invoke({\"question\": \"What is expression language?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c013e2-241a-4def-9aa6-ccb34273eeb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
