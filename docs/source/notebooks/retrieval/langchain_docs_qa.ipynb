{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
            "metadata": {},
            "source": [
                "# Q&A over LangChain Docs\n",
                "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/retrieval/langchain_docs_qa.ipynb)\n",
                "\n",
                "Let's evaluate your architecture on a Q&A dataset for the LangChain python docs. For more examples of how to test different embeddings, indexing strategies, and architectures, see the [Evaluating RAG Architectures on Benchmark Tasks](./comparing_techniques.ipynb) notebook.\n",
                "\n",
                "## Pre-requisites\n",
                "\n",
                "We will install quite a few prerequisites for this example since we are comparing many techniques and models.\n",
                "\n",
                "We will be using LangSmith to capture the evaluation traces. You can make a free account at [smith.langchain.com](https://smith.langchain.com/). Once you've done so, you can make an API key and set it below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "9f44b59b",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "%pip install -U --quiet langchain langsmith langchainhub langchain_benchmarks\n",
                "%pip install --quiet chromadb openai huggingface pandas langchain_experimental sentence_transformers pyarrow anthropic tiktoken"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0aae13f6-cd40-41e6-bd02-bd683e91cbff",
            "metadata": {},
            "source": [
                "For this code to work, please configure LangSmith environment variables with your credentials."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
                "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls_...\"  # Your API key"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Update these with your own API keys\n",
                "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\n",
                "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
                "# Silence warnings from HuggingFace\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
            "metadata": {},
            "source": [
                "## Review Q&A Tasks\n",
                "\n",
                "The registry provides configurations to test out common architectures on curated datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from langchain_benchmarks import clone_public_dataset, registry"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "3644d211-382e-41aa-b282-21b01d28fc35",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table>\n",
                            "<thead>\n",
                            "<tr><th>Name                   </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n",
                            "</thead>\n",
                            "<tbody>\n",
                            "<tr><td>LangChain Docs Q&A     </td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
                            "\n",
                            "The environment provides the documents and the retriever information.\n",
                            "\n",
                            "Each example is composed of a question and reference answer.\n",
                            "\n",
                            "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
                            "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
                            "<tr><td>Semi-structured Reports</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d\" target=\"_blank\" rel=\"noopener\">c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</a></td><td>Questions and answers based on PDFs containing tables and charts.\n",
                            "\n",
                            "The task provides the raw documents as well as factory methods to easily index them\n",
                            "and create a retriever.\n",
                            "\n",
                            "Each example is composed of a question and reference answer.\n",
                            "\n",
                            "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
                            "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
                            "</tbody>\n",
                            "</table>"
                        ],
                        "text/plain": [
                            "Registry(tasks=[RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x16a5802c0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x16a580360>, 'hyde': <function _chroma_hyde_retriever_factory at 0x16a580400>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x12fc37ce0>}, get_docs=<function load_cached_docs at 0x12fc377e0>), RetrievalTask(name='Semi-structured Reports', dataset_id='https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x16a580ae0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x16a580b80>, 'hyde': <function _chroma_hyde_retriever_factory at 0x16a580c20>}, architecture_factories={}, get_docs=<function load_docs at 0x16a580a40>)])"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "registry = registry.filter(Type=\"RetrievalTask\")\n",
                "registry"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "671282f8-c455-4390-b018-e53bbd833093",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table>\n",
                            "<tbody>\n",
                            "<tr><td>Name                  </td><td>LangChain Docs Q&A                                                                                                                                         </td></tr>\n",
                            "<tr><td>Type                  </td><td>RetrievalTask                                                                                                                                              </td></tr>\n",
                            "<tr><td>Dataset ID            </td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td></tr>\n",
                            "<tr><td>Description           </td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
                            "\n",
                            "The environment provides the documents and the retriever information.\n",
                            "\n",
                            "Each example is composed of a question and reference answer.\n",
                            "\n",
                            "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
                            "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).                                                                                                                                                            </td></tr>\n",
                            "<tr><td>Retriever Factories   </td><td>basic, parent-doc, hyde                                                                                                                                    </td></tr>\n",
                            "<tr><td>Architecture Factories</td><td>conversational-retrieval-qa                                                                                                                                </td></tr>\n",
                            "<tr><td>get_docs              </td><td><function load_cached_docs at 0x12fc377e0>                                                                                                                 </td></tr>\n",
                            "</tbody>\n",
                            "</table>"
                        ],
                        "text/plain": [
                            "RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x16a5802c0>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x16a580360>, 'hyde': <function _chroma_hyde_retriever_factory at 0x16a580400>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x12fc37ce0>}, get_docs=<function load_cached_docs at 0x12fc377e0>)"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "langchain_docs = registry[\"LangChain Docs Q&A\"]\n",
                "langchain_docs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset LangChain Docs Q&A already exists. Skipping.\n",
                        "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/3f29798f-5939-4643-bd99-008ca66b72ed.\n"
                    ]
                }
            ],
            "source": [
                "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "c58247f5-b9bd-4cc5-9632-78bc21bb10b4",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4fc93abde64d43c99ffa0eb5374dca86",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from langchain.embeddings import HuggingFaceEmbeddings\n",
                "\n",
                "embeddings = HuggingFaceEmbeddings(\n",
                "    model_name=\"thenlper/gte-base\",\n",
                "    model_kwargs = {'device': 0}, # Comment out to use CPU\n",
                ")\n",
                "\n",
                "docs = langchain_docs.get_docs()\n",
                "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
                "# Indexes the documents with the specified embeddings\n",
                "# Note that this does not apply any chunking to the docs,\n",
                "# which means the documents can be of arbitrary length\n",
                "retriever = retriever_factory(embeddings, docs=docs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "41e64350-63a7-4e7d-8e03-7dc459c444cc",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from operator import itemgetter\n",
                "from typing import Sequence\n",
                "\n",
                "from langchain.chat_models import ChatAnthropic\n",
                "from langchain.prompts import ChatPromptTemplate\n",
                "from langchain.schema.document import Document\n",
                "from langchain.schema.output_parser import StrOutputParser\n",
                "from langchain.schema.runnable import RunnableLambda\n",
                "from langchain.schema.runnable.passthrough import RunnableAssign\n",
                "\n",
                "\n",
                "def format_docs(docs: Sequence[Document]) -> str:\n",
                "    formatted_docs = []\n",
                "    for i, doc in enumerate(docs):\n",
                "        doc_string = (\n",
                "            f\"<document index='{i}'>\\n\"\n",
                "            f\"<source>{doc.metadata.get('source')}</source>\\n\"\n",
                "            f\"<doc_content>{doc.page_content}</doc_content>\\n\"\n",
                "            \"</document>\"\n",
                "        )\n",
                "        formatted_docs.append(doc_string)\n",
                "    formatted_str = \"\\n\".join(formatted_docs)\n",
                "    return f\"<documents>\\n{formatted_str}\\n</documents>\"\n",
                "\n",
                "\n",
                "prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\n",
                "            \"system\",\n",
                "            \"You are an AI assistant answering questions about LangChain.\"\n",
                "            \"\\n{context}\\n\"\n",
                "            \"Respond solely based on the document content.\",\n",
                "        ),\n",
                "        (\"human\", \"{question}\"),\n",
                "    ]\n",
                ")\n",
                "llm = ChatAnthropic(model=\"claude-2.1\", temperature=1)\n",
                "\n",
                "response_generator = (prompt | llm | StrOutputParser()).with_config(\n",
                "    run_name=\"GenerateResponse\",\n",
                ")\n",
                "chain = (\n",
                "    RunnableAssign(\n",
                "        {\n",
                "            \"context\": (itemgetter(\"question\") | retriever | format_docs).with_config(\n",
                "                run_name=\"FormatDocs\"\n",
                "            )\n",
                "        }\n",
                "    )\n",
                "    | response_generator\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "10a1fca9-d356-4cff-93a9-c4f63944e57d",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "' Unfortunately, I do not have any documents to reference information about expression language. As an AI assistant without access to external information, I can only respond based on the content provided to me. If you could provide me with some documents that describe expression language, I would be happy to summarize or share information from those documents to answer your question. Please feel free to provide any additional context or documents that may allow me to assist further.'"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chain.invoke({\"question\": \"What's expression language?\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
            "metadata": {},
            "source": [
                "### Evaluate\n",
                "\n",
                "Let's evaluate your RAG architecture on the dataset now."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "513042fe-2878-44f8-ae84-05b9d521c1de",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from langsmith.client import Client\n",
                "\n",
                "from langchain_benchmarks.rag import get_eval_config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "View the evaluation results for project 'only-man-12' at:\n",
                        "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/c915fa65-2be0-42ad-8038-9a9fe3a0a879?eval=true\n",
                        "\n",
                        "View all tests for Dataset LangChain Docs Q&A at:\n",
                        "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/3f29798f-5939-4643-bd99-008ca66b72ed\n",
                        "[------------------------------------------------->] 86/86\n",
                        " Eval quantiles:\n",
                        "                                          inputs.question  \\\n",
                        "count                                                  86   \n",
                        "unique                                                 86   \n",
                        "top     in code, how can i add a system message at the...   \n",
                        "freq                                                    1   \n",
                        "mean                                                  NaN   \n",
                        "std                                                   NaN   \n",
                        "min                                                   NaN   \n",
                        "25%                                                   NaN   \n",
                        "50%                                                   NaN   \n",
                        "75%                                                   NaN   \n",
                        "max                                                   NaN   \n",
                        "\n",
                        "        feedback.embedding_cosine_distance  feedback.score_string:accuracy  \\\n",
                        "count                            86.000000                       86.000000   \n",
                        "unique                                 NaN                             NaN   \n",
                        "top                                    NaN                             NaN   \n",
                        "freq                                   NaN                             NaN   \n",
                        "mean                              0.190418                        0.177907   \n",
                        "std                               0.045291                        0.176503   \n",
                        "min                               0.074583                        0.100000   \n",
                        "25%                               0.154158                        0.100000   \n",
                        "50%                               0.190138                        0.100000   \n",
                        "75%                               0.222883                        0.100000   \n",
                        "max                               0.289047                        1.000000   \n",
                        "\n",
                        "        feedback.faithfulness error  execution_time  \n",
                        "count               82.000000     0       86.000000  \n",
                        "unique                    NaN     0             NaN  \n",
                        "top                       NaN   NaN             NaN  \n",
                        "freq                      NaN   NaN             NaN  \n",
                        "mean                 0.939024   NaN        9.605034  \n",
                        "std                  0.199231   NaN        3.323173  \n",
                        "min                  0.100000   NaN        4.748375  \n",
                        "25%                  1.000000   NaN        7.521995  \n",
                        "50%                  1.000000   NaN        8.637612  \n",
                        "75%                  1.000000   NaN       10.116563  \n",
                        "max                  1.000000   NaN       18.631366  \n"
                    ]
                }
            ],
            "source": [
                "client = Client()\n",
                "RAG_EVALUATION = get_eval_config()\n",
                "\n",
                "test_run = client.run_on_dataset(\n",
                "    dataset_name=langchain_docs.name,\n",
                "    llm_or_chain_factory=chain,\n",
                "    evaluation=RAG_EVALUATION,\n",
                "    verbose=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "e86578d5-be5c-4bcd-9dcb-35280eeed3f9",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>inputs.question</th>\n",
                            "      <th>feedback.embedding_cosine_distance</th>\n",
                            "      <th>feedback.score_string:accuracy</th>\n",
                            "      <th>feedback.faithfulness</th>\n",
                            "      <th>error</th>\n",
                            "      <th>execution_time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>86</td>\n",
                            "      <td>86.000000</td>\n",
                            "      <td>86.000000</td>\n",
                            "      <td>82.000000</td>\n",
                            "      <td>0</td>\n",
                            "      <td>86.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>unique</th>\n",
                            "      <td>86</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>top</th>\n",
                            "      <td>in code, how can i add a system message at the...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>freq</th>\n",
                            "      <td>1</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.190418</td>\n",
                            "      <td>0.177907</td>\n",
                            "      <td>0.939024</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>9.605034</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.045291</td>\n",
                            "      <td>0.176503</td>\n",
                            "      <td>0.199231</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>3.323173</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.074583</td>\n",
                            "      <td>0.100000</td>\n",
                            "      <td>0.100000</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>4.748375</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.154158</td>\n",
                            "      <td>0.100000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>7.521995</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.190138</td>\n",
                            "      <td>0.100000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>8.637612</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.222883</td>\n",
                            "      <td>0.100000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>10.116563</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.289047</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>18.631366</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                          inputs.question  \\\n",
                            "count                                                  86   \n",
                            "unique                                                 86   \n",
                            "top     in code, how can i add a system message at the...   \n",
                            "freq                                                    1   \n",
                            "mean                                                  NaN   \n",
                            "std                                                   NaN   \n",
                            "min                                                   NaN   \n",
                            "25%                                                   NaN   \n",
                            "50%                                                   NaN   \n",
                            "75%                                                   NaN   \n",
                            "max                                                   NaN   \n",
                            "\n",
                            "        feedback.embedding_cosine_distance  feedback.score_string:accuracy  \\\n",
                            "count                            86.000000                       86.000000   \n",
                            "unique                                 NaN                             NaN   \n",
                            "top                                    NaN                             NaN   \n",
                            "freq                                   NaN                             NaN   \n",
                            "mean                              0.190418                        0.177907   \n",
                            "std                               0.045291                        0.176503   \n",
                            "min                               0.074583                        0.100000   \n",
                            "25%                               0.154158                        0.100000   \n",
                            "50%                               0.190138                        0.100000   \n",
                            "75%                               0.222883                        0.100000   \n",
                            "max                               0.289047                        1.000000   \n",
                            "\n",
                            "        feedback.faithfulness error  execution_time  \n",
                            "count               82.000000     0       86.000000  \n",
                            "unique                    NaN     0             NaN  \n",
                            "top                       NaN   NaN             NaN  \n",
                            "freq                      NaN   NaN             NaN  \n",
                            "mean                 0.939024   NaN        9.605034  \n",
                            "std                  0.199231   NaN        3.323173  \n",
                            "min                  0.100000   NaN        4.748375  \n",
                            "25%                  1.000000   NaN        7.521995  \n",
                            "50%                  1.000000   NaN        8.637612  \n",
                            "75%                  1.000000   NaN       10.116563  \n",
                            "max                  1.000000   NaN       18.631366  "
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_run.get_aggregate_feedback()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "01811b97-cb28-42a6-920a-7a700f77f19d",
            "metadata": {},
            "source": [
                "## Evaluate with a default factory\n",
                "\n",
                "The task can define default chain and retriever \"factories\", whic provide a default architecture that you can modify by choosing the llms, prompts, etc. Let's try the `conversational-retrieval-qa` factory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "f4d2e139-2653-4f7b-944b-91ef52f43d3e",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Factory for creating a conversational retrieval QA chain\n",
                "chain_factory = langchain_docs.architecture_factories[\"conversational-retrieval-qa\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "6e938e5b-c430-4ab1-ab7d-84c33f83bdc5",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "9f9be718-64f0-4706-9527-240a1cdb3ecb",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\" <context>\\n\\nNo search results have been provided.\\n\\n</context>\\n\\nHmm, I'm not sure.\""
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain.chat_models import ChatAnthropic\n",
                "\n",
                "# Example\n",
                "llm = ChatAnthropic(model=\"claude-2\", temperature=1)\n",
                "\n",
                "\n",
                "chain = chain_factory(retriever, llm=llm)\n",
                "\n",
                "chain.invoke({\"question\": \"What is expression language?\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "e9c013e2-241a-4def-9aa6-ccb34273eeb9",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "View the evaluation results for project 'bold-increase-73' at:\n",
                        "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/ec954070-30ee-47e3-acf7-698f3c70c20f?eval=true\n",
                        "\n",
                        "View all tests for Dataset LangChain Docs Q&A at:\n",
                        "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/3f29798f-5939-4643-bd99-008ca66b72ed\n",
                        "[------------------------------------------------->] 86/86\n",
                        " Eval quantiles:\n",
                        "                                          inputs.question  \\\n",
                        "count                                                  86   \n",
                        "unique                                                 86   \n",
                        "top     in code, how can i add a system message at the...   \n",
                        "freq                                                    1   \n",
                        "mean                                                  NaN   \n",
                        "std                                                   NaN   \n",
                        "min                                                   NaN   \n",
                        "25%                                                   NaN   \n",
                        "50%                                                   NaN   \n",
                        "75%                                                   NaN   \n",
                        "max                                                   NaN   \n",
                        "\n",
                        "        feedback.embedding_cosine_distance  feedback.score_string:accuracy  \\\n",
                        "count                            86.000000                       86.000000   \n",
                        "unique                                 NaN                             NaN   \n",
                        "top                                    NaN                             NaN   \n",
                        "freq                                   NaN                             NaN   \n",
                        "mean                              0.194922                        0.202326   \n",
                        "std                               0.053206                        0.180833   \n",
                        "min                               0.071091                        0.100000   \n",
                        "25%                               0.152611                        0.100000   \n",
                        "50%                               0.191152                        0.100000   \n",
                        "75%                               0.223243                        0.300000   \n",
                        "max                               0.328942                        0.700000   \n",
                        "\n",
                        "        feedback.faithfulness error  execution_time  \n",
                        "count               85.000000     0       86.000000  \n",
                        "unique                    NaN     0             NaN  \n",
                        "top                       NaN   NaN             NaN  \n",
                        "freq                      NaN   NaN             NaN  \n",
                        "mean                 0.824706   NaN        9.743528  \n",
                        "std                  0.289048   NaN        4.399820  \n",
                        "min                  0.100000   NaN        4.208420  \n",
                        "25%                  0.700000   NaN        6.018769  \n",
                        "50%                  1.000000   NaN        8.086979  \n",
                        "75%                  1.000000   NaN       14.081097  \n",
                        "max                  1.000000   NaN       18.671288  \n"
                    ]
                }
            ],
            "source": [
                "from functools import partial\n",
                "\n",
                "test_run = client.run_on_dataset(\n",
                "    dataset_name=langchain_docs.name,\n",
                "    llm_or_chain_factory=partial(chain_factory, retriever=retriever, llm=llm),\n",
                "    evaluation=RAG_EVALUATION,\n",
                "    verbose=True,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
