{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# Q&A over LangChain Docs\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/retrieval/langchain_docs_qa.ipynb) (Note: GPU runtime recommended in Collab for faster indexing)\n",
    "\n",
    "Let's evaluate your architecture on a Q&A dataset for the LangChain python docs. For more examples of how to test different embeddings, indexing strategies, and architectures, see the [Evaluating RAG Architectures on Benchmark Tasks](./comparing_techniques.ipynb) notebook.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "We will install quite a few prerequisites for this example since we are comparing many techniques and models.\n",
    "\n",
    "We will be using LangSmith to capture the evaluation traces. You can make a free account at [smith.langchain.com](https://smith.langchain.com/). Once you've done so, you can make an API key and set it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44b59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet langchain langsmith langchainhub langchain_benchmarks\n",
    "%pip install --quiet chromadb openai huggingface pandas langchain_experimental sentence_transformers pyarrow anthropic tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae13f6-cd40-41e6-bd02-bd683e91cbff",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b518cf-99fb-44be-8acb-ee0a8ba62272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls_...\"  # Your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4292ee8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update these with your own API keys\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "# Silence warnings from HuggingFace\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbf17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique run ID for this experiment\n",
    "run_uid = uuid.uuid4().hex[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a666d-8bf5-4bfd-8b20-8b7defdb8cd5",
   "metadata": {},
   "source": [
    "## Review Q&A Tasks\n",
    "\n",
    "The registry provides configurations to test out common architectures on curated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39159d0-9ea1-414f-a9d8-4a7b22b3d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3644d211-382e-41aa-b282-21b01d28fc35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name                   </th><th>Type         </th><th>Dataset ID                                                                                                                                                 </th><th>Description  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LangChain Docs Q&A     </td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
       "<tr><td>Semi-structured Reports</td><td>RetrievalTask</td><td><a href=\"https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d\" target=\"_blank\" rel=\"noopener\">c47d9617-ab99-4d6e-a6e6-92b8daf85a7d</a></td><td>Questions and answers based on PDFs containing tables and charts.\n",
       "\n",
       "The task provides the raw documents as well as factory methods to easily index them\n",
       "and create a retriever.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Registry(tasks=[RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x117478220>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x1174782c0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x117478360>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x116b44220>}, get_docs=<function load_cached_docs at 0x116edd800>), RetrievalTask(name='Semi-structured Reports', dataset_id='https://smith.langchain.com/public/c47d9617-ab99-4d6e-a6e6-92b8daf85a7d/d', description=\"Questions and answers based on PDFs containing tables and charts.\\n\\nThe task provides the raw documents as well as factory methods to easily index them\\nand create a retriever.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x117478a40>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x117478ae0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x117478b80>}, architecture_factories={}, get_docs=<function load_docs at 0x1174789a0>)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry = registry.filter(Type=\"RetrievalTask\")\n",
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671282f8-c455-4390-b018-e53bbd833093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name                  </td><td>LangChain Docs Q&A                                                                                                                                         </td></tr>\n",
       "<tr><td>Type                  </td><td>RetrievalTask                                                                                                                                              </td></tr>\n",
       "<tr><td>Dataset ID            </td><td><a href=\"https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d\" target=\"_blank\" rel=\"noopener\">452ccafc-18e1-4314-885b-edd735f17b9d</a></td></tr>\n",
       "<tr><td>Description           </td><td>Questions and answers based on a snapshot of the LangChain python docs.\n",
       "\n",
       "The environment provides the documents and the retriever information.\n",
       "\n",
       "Each example is composed of a question and reference answer.\n",
       "\n",
       "Success is measured based on the accuracy of the answer relative to the reference answer.\n",
       "We also measure the faithfulness of the model's response relative to the retrieved documents (if any).                                                                                                                                                            </td></tr>\n",
       "<tr><td>Retriever Factories   </td><td>basic, parent-doc, hyde                                                                                                                                    </td></tr>\n",
       "<tr><td>Architecture Factories</td><td>conversational-retrieval-qa                                                                                                                                </td></tr>\n",
       "<tr><td>get_docs              </td><td><function load_cached_docs at 0x116edd800>                                                                                                                 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "RetrievalTask(name='LangChain Docs Q&A', dataset_id='https://smith.langchain.com/public/452ccafc-18e1-4314-885b-edd735f17b9d/d', description=\"Questions and answers based on a snapshot of the LangChain python docs.\\n\\nThe environment provides the documents and the retriever information.\\n\\nEach example is composed of a question and reference answer.\\n\\nSuccess is measured based on the accuracy of the answer relative to the reference answer.\\nWe also measure the faithfulness of the model's response relative to the retrieved documents (if any).\\n\", retriever_factories={'basic': <function _chroma_retriever_factory at 0x117478220>, 'parent-doc': <function _chroma_parent_document_retriever_factory at 0x1174782c0>, 'hyde': <function _chroma_hyde_retriever_factory at 0x117478360>}, architecture_factories={'conversational-retrieval-qa': <function default_response_chain at 0x116b44220>}, get_docs=<function load_cached_docs at 0x116edd800>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_docs = registry[\"LangChain Docs Q&A\"]\n",
    "langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70369f67-deb4-467a-801a-6d38c3d0460d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LangChain Docs Q&A already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/3f29798f-5939-4643-bd99-008ca66b72ed.\n"
     ]
    }
   ],
   "source": [
    "clone_public_dataset(langchain_docs.dataset_id, dataset_name=langchain_docs.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58247f5-b9bd-4cc5-9632-78bc21bb10b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18f09419bc14e0c92cac248041c1bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"thenlper/gte-base\",\n",
    "    model_kwargs={\"device\": 0},  # Comment out to use CPU\n",
    ")\n",
    "\n",
    "docs = langchain_docs.get_docs()\n",
    "retriever_factory = langchain_docs.retriever_factories[\"basic\"]\n",
    "# Indexes the documents with the specified embeddings\n",
    "# Note that this does not apply any chunking to the docs,\n",
    "# which means the documents can be of arbitrary length\n",
    "retriever = retriever_factory(embeddings, docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e64350-63a7-4e7d-8e03-7dc459c444cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "\n",
    "\n",
    "def format_docs(docs: Sequence[Document]) -> str:\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_string = (\n",
    "            f\"<document index='{i}'>\\n\"\n",
    "            f\"<source>{doc.metadata.get('source')}</source>\\n\"\n",
    "            f\"<doc_content>{doc.page_content}</doc_content>\\n\"\n",
    "            \"</document>\"\n",
    "        )\n",
    "        formatted_docs.append(doc_string)\n",
    "    formatted_str = \"\\n\".join(formatted_docs)\n",
    "    return f\"<documents>\\n{formatted_str}\\n</documents>\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant answering questions about LangChain.\"\n",
    "            \"\\n{context}\\n\"\n",
    "            \"Respond solely based on the document content.\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatAnthropic(model=\"claude-2.1\", temperature=1)\n",
    "\n",
    "response_generator = (prompt | llm | StrOutputParser()).with_config(\n",
    "    run_name=\"GenerateResponse\",\n",
    ")\n",
    "chain = (\n",
    "    RunnableAssign(\n",
    "        {\n",
    "            \"context\": (itemgetter(\"question\") | retriever | format_docs).with_config(\n",
    "                run_name=\"FormatDocs\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    | response_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a1fca9-d356-4cff-93a9-c4f63944e57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the documents, LangChain Expression Language (LCEL) is a declarative way to easily compose chains together in LangChain. \\n\\nSome key things it enables:\\n\\n- Streaming support - gets first output tokens quickly, streams incremental results\\n- Async support - can call LCEL chains sync or async, enabling prototypes and production use\\n- Optimized parallel execution - automatically runs steps in parallel when possible\\n- Retries and fallbacks - add reliability to chains\\n- Access intermediate results - inspect mid-chain outputs \\n- Input/output schemas - gets schemas for inputs and outputs\\n- LangSmith tracing - logs all steps for observability\\n- LangServe deployment - easily deploy any LCEL chain\\n\\nSo in summary, LCEL provides a way to build chains that work great in prototypes and can scale directly up to production environments. The language aims to make it easy to compose small building blocks into complex, reliable chains.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What's expression language?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e4b0-8e67-418a-840c-470fcde42df0",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Let's evaluate your RAG architecture on the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "513042fe-2878-44f8-ae84-05b9d521c1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.rag import get_eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab7514e-a6ef-4c21-b90f-d9cbefcf5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_uid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[1;32m      2\u001b[0m RAG_EVALUATION \u001b[38;5;241m=\u001b[39m get_eval_config()\n\u001b[1;32m      4\u001b[0m test_run \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mrun_on_dataset(\n\u001b[1;32m      5\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mlangchain_docs\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m      6\u001b[0m     llm_or_chain_factory\u001b[38;5;241m=\u001b[39mchain,\n\u001b[1;32m      7\u001b[0m     evaluation\u001b[38;5;241m=\u001b[39mRAG_EVALUATION,\n\u001b[0;32m----> 8\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-2 qa-chain simple-index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrun_uid\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     project_metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     },\n\u001b[1;32m     12\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_uid' is not defined"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "RAG_EVALUATION = get_eval_config()\n",
    "\n",
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    project_name=f\"claude-2 qa-chain simple-index {run_uid}\",\n",
    "    project_metadata={\n",
    "        \"index_method\": \"basic\",\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86578d5-be5c-4bcd-9dcb-35280eeed3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01811b97-cb28-42a6-920a-7a700f77f19d",
   "metadata": {},
   "source": [
    "## Evaluate with a default factory\n",
    "\n",
    "The task can define default chain and retriever \"factories\", which provide a default architecture that you can modify by choosing the llms, prompts, etc. Let's try the `conversational-retrieval-qa` factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2e139-2653-4f7b-944b-91ef52f43d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Factory for creating a conversational retrieval QA chain\n",
    "chain_factory = langchain_docs.architecture_factories[\"conversational-retrieval-qa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9be718-64f0-4706-9527-240a1cdb3ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "\n",
    "# Example\n",
    "llm = ChatAnthropic(model=\"claude-2\", temperature=1)\n",
    "\n",
    "\n",
    "chain = chain_factory(retriever, llm=llm)\n",
    "\n",
    "chain.invoke({\"question\": \"What is expression language?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c013e2-241a-4def-9aa6-ccb34273eeb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run = client.run_on_dataset(\n",
    "    dataset_name=langchain_docs.name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=RAG_EVALUATION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c1d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_run.get_aggregate_feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa364667-6f3a-4eb1-94ad-c07be99cb095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
