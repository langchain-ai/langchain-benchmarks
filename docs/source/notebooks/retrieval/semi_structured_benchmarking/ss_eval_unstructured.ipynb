{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10b060d-6363-4669-8866-7c8ef1103a38",
   "metadata": {},
   "source": [
    "# Semi-structured eval: Unstructured + Multi-vector retriever\n",
    "\n",
    "We will test retrival of table information from the `Semi-structured Reports` dataset using various methods.\n",
    "\n",
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46dade-a12b-4ee4-abfa-c5b071a7eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langsmith langchain_benchmarks\n",
    "%pip install --quiet chromadb openai \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daca152-b63b-4403-9b46-66ff9ab2a275",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dafb546c-32a1-46e9-b0aa-9b4b2c439324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_benchmarks import registry\n",
    "from langchain_benchmarks.rag.tasks.semi_structured_reports import get_file_names\n",
    "\n",
    "# Task\n",
    "task = registry[\"Semi-structured Reports\"]\n",
    "\n",
    "# Files used\n",
    "paths = list(get_file_names())\n",
    "files = [str(p) for p in paths]\n",
    "\n",
    "### TODO: Replace when dataset is updated\n",
    "dir = \"/Users/rlm/Desktop/Eval_Sets/semi_structured_reports/\"\n",
    "files = [f for f in os.listdir(dir) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce580b-cdbf-4e09-8273-35a9e0b62307",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "Use table-aware splitting following cookbook [here](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb).\n",
    "\n",
    "In addition to the below pip packages, you will also need [poppler](https://pdf2image.readthedocs.io/en/latest/installation.html) and [tesseract](https://tesseract-ocr.github.io/tessdoc/Installation.html) in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63985459-b295-422a-a5ca-1fba86049964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "def categorize_elements(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    Categorize extracted elements from a PDF into tables and texts.\n",
    "    raw_pdf_elements: List of unstructured.documents.elements\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))\n",
    "    return texts, tables\n",
    "\n",
    "def generate_doc_summary(file):\n",
    "    \"\"\"\n",
    "    Create a doc summary\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked extracting two attributes \\\n",
    "    from financial documents. (1) Tell me the company that the document is \\\n",
    "    focused on. (2) Look at any tables in the document and tell me the units \\ \n",
    "    of the table. Many table will have '(In thousands)' or '(in millions)' prior \\\n",
    "    to the table text. Provide these two  {document} \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "    # Text summary chain\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "    summarize_chain = {\"document\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Load doc\n",
    "    loader = PyPDFLoader(file)\n",
    "    pdf_pages = loader.load()\n",
    "    texts = [t.page_content for t in pdf_pages]\n",
    "    text_string = \" \".join(texts)\n",
    "    summary = summarize_chain.invoke({\"document\": text_string})\n",
    "    return summary\n",
    "\n",
    "\n",
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing a tables or text chunk for retrieval. \\\n",
    "    The summary will be embedded and used to retrieve the raw tables or text chunk. Give a concise summary. \\\n",
    "    For tables, list as many of rows and column names as possible so we know what is captured in the table. \\ \n",
    "    Do not worry about summarizing quantitative results in the table. Table or text: {element} \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "    # Text summary chain\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "def parse_pdf_unstructured(file):\n",
    "    \"\"\"\n",
    "    Get tables, texts from pdf\n",
    "    \"\"\"\n",
    "    # Get elements\n",
    "    unstructured_elements = partition_pdf(\n",
    "        filename=file,\n",
    "        extract_images_in_pdf=False,\n",
    "        infer_table_structure=True,\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=4000,\n",
    "        new_after_n_chars=3800,\n",
    "        combine_text_under_n_chars=2000,\n",
    "        image_output_dir_path=os.path.dirname(file),\n",
    "    )\n",
    "\n",
    "    # Categorize elements by type\n",
    "    texts, tables = categorize_elements(unstructured_elements)\n",
    "    print(f\"There are {len(tables)} tables\")\n",
    "    print(f\"There are {len(texts)} text elements\")\n",
    "    return texts, tables\n",
    "\n",
    "\n",
    "texts = []\n",
    "tables = []\n",
    "text_summaries = []\n",
    "table_summaries = []\n",
    "\n",
    "for fi in files:\n",
    "\n",
    "    # Generate document summary\n",
    "    doc_summary = generate_doc_summary(dir + fi)\n",
    "\n",
    "    # Get texts, tables\n",
    "    doc_texts, doc_tables = parse_pdf_unstructured(dir + fi)\n",
    "    \n",
    "    # Enforce a specific token size for texts to summarize larger chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=4000, chunk_overlap=0\n",
    "    )\n",
    "    joined_doc_texts = \" \".join(doc_texts)\n",
    "    doc_texts = text_splitter.split_text(joined_doc_texts)\n",
    "    \n",
    "    # Get text, table summaries\n",
    "    doc_text_summaries, doc_table_summaries = generate_text_summaries(\n",
    "        doc_texts, doc_tables, summarize_texts=False\n",
    "    )\n",
    "\n",
    "    # Add doc summary to table summary to preserve context\n",
    "    doc_table_summaries = [\n",
    "        doc_summary + \"\\n\\n Here is a summary of a table within this doc: \\n\\n\" + t\n",
    "        for t in doc_table_summaries\n",
    "    ]\n",
    "\n",
    "    # Append table with doc summary to give units for values\n",
    "    doc_tables = [\n",
    "        doc_summary + \"\\n\\n Here is a table within this doc: \\n\\n\" + t\n",
    "        for t in doc_tables\n",
    "    ]\n",
    "\n",
    "    # Add to lists\n",
    "    texts.extend(doc_texts)\n",
    "    tables.extend(doc_tables)\n",
    "    text_summaries.extend(doc_text_summaries)\n",
    "    table_summaries.extend(doc_table_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8e2db-98da-4867-9c1a-c1d59f2b3d41",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c898d14-1ca6-477f-93bd-3ec942f02748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "def create_multi_vector_retriever(\n",
    "    vectorstore,\n",
    "    text_summaries=None,\n",
    "    texts=None,\n",
    "    table_summaries=None,\n",
    "    tables=None,\n",
    "    image_summaries=None,\n",
    "    images=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create retriever that indexes summaries, but returns raw images or texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the storage layer\n",
    "    store = InMemoryStore()\n",
    "    id_key = \"doc_id\"\n",
    "\n",
    "    # Create the multi-vector retriever\n",
    "    retriever = MultiVectorRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        docstore=store,\n",
    "        id_key=id_key,\n",
    "    )\n",
    "\n",
    "    # Helper function to add documents to the vectorstore and docstore\n",
    "    def add_documents(retriever, doc_summaries, doc_contents):\n",
    "        doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
    "        summary_docs = [\n",
    "            Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "            for i, s in enumerate(doc_summaries)\n",
    "        ]\n",
    "        retriever.vectorstore.add_documents(summary_docs)\n",
    "        retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "\n",
    "    # Add texts, tables, and images\n",
    "    if text_summaries:\n",
    "        add_documents(retriever, text_summaries, texts)\n",
    "    if table_summaries:\n",
    "        add_documents(retriever, table_summaries, tables)\n",
    "    if image_summaries:\n",
    "        add_documents(retriever, image_summaries, images)\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e3bee7d-8cf4-4896-8111-323f4ddcbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vectorstore to use to index the summaries\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"unstructured-tables-updated\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever_unstructured = create_multi_vector_retriever(\n",
    "    vectorstore,\n",
    "    table_summaries=table_summaries,\n",
    "    tables=tables,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb11d59-677a-47a8-8225-0be5c85325db",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "705a9e67-09b1-47a6-8280-db4a77052a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "def rag_chain(retriever):\n",
    "    \"\"\"\n",
    "    RAG chain\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt template\n",
    "    template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "\n",
    "    # RAG pipeline\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "\n",
    "# Create RAG chain\n",
    "chain = rag_chain(retriever_unstructured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35eefd-eef1-4c51-a5d8-03f45b2b21d9",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688f83ba-ca5f-4f98-acf4-e2a233f8ea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'd4c8-unstructured' at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/8ea15254-5fa3-4141-8cac-4d4eefc89614/compare?selectedSessions=781ee8a7-ed7c-442a-ba35-4b5faacb64b6\n",
      "\n",
      "View all tests for Dataset Semi-Structured-Eval-v9 at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/8ea15254-5fa3-4141-8cac-4d4eefc89614\n",
      "[------------------------------------------------->] 25/25"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>feedback.COT Contextual Accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>The Non-GAAP gross margin for Datadog for the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.964517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.520781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.120215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.797705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.689105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.590007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   output  \\\n",
       "count                                                  25   \n",
       "unique                                                 25   \n",
       "top     The Non-GAAP gross margin for Datadog for the ...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "        feedback.COT Contextual Accuracy error  execution_time  \n",
       "count                               25.0     0       25.000000  \n",
       "unique                               NaN     0             NaN  \n",
       "top                                  NaN   NaN             NaN  \n",
       "freq                                 NaN   NaN             NaN  \n",
       "mean                                 0.4   NaN        5.964517  \n",
       "std                                  0.5   NaN        0.963154  \n",
       "min                                  0.0   NaN        4.520781  \n",
       "25%                                  0.0   NaN        5.120215  \n",
       "50%                                  0.0   NaN        5.797705  \n",
       "75%                                  1.0   NaN        6.689105  \n",
       "max                                  1.0   NaN        8.590007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from langsmith.client import Client\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "# Config\n",
    "client = Client()\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"cot_qa\"],\n",
    ")\n",
    "\n",
    "# Experiments\n",
    "chain_map = {\n",
    "    \"unstructured\": chain,\n",
    "}\n",
    "\n",
    "# Run evaluation\n",
    "run_id = uuid.uuid4().hex[:4]\n",
    "test_runs = {}\n",
    "for project_name, chain in chain_map.items():\n",
    "    test_runs[project_name] = client.run_on_dataset(\n",
    "        # dataset_name=task.name,\n",
    "        dataset_name=\"Semi-Structured-Eval-v9\",\n",
    "        llm_or_chain_factory=lambda: (lambda x: x[\"question\"]) | chain,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_name=f\"{run_id}-{project_name}\",\n",
    "        project_metadata={\"chain\": project_name},\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
