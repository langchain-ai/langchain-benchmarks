

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Model Registry &#8212; LangChain Benchmarks 0.0.12</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/models';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Datasets" href="datasets.html" />
    <link rel="prev" title="Getting Started" href="getting_started.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">LangChain Benchmarks 0.0.12</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    ðŸ¦œðŸ’¯ LangChain Benchmarks
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tool Usage</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="tool_usage/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_usage/relational_data.html">Relational Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_usage/multiverse_math.html">Multiverse Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_usage/typewriter_1.html">Typewriter: Single Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_usage/typewriter_26.html">Typewriter: 26 Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_usage/benchmark_all_tasks.html">Benchmark All Tasks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Extraction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="extraction/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="extraction/email.html">Email Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="extraction/chat_extraction.html">Chat Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="extraction/high_cardinality.html">Extracting high-cardinality categoricals</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">RAG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="retrieval/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/langchain_docs_qa.html">Q&amp;A over LangChain Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/semi_structured_benchmarking/semi_structured.html">Semi-structured RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/semi_structured_benchmarking/ss_eval_chunk_sizes.html">Semi-structured eval: Chunk size tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/semi_structured_benchmarking/ss_eval_long_context.html">Semi-structured eval: Long-context</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/semi_structured_benchmarking/ss_eval_multi_vector.html">Semi-structured eval: Multi vector</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/multi_modal_benchmarking/multi_modal_eval_baseline.html">Multi-modal eval: Baseline</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/multi_modal_benchmarking/multi_modal_eval.html">Multi-modal eval: GPT-4 w/ multi-modal embeddings and multi-vector retriever</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval/comparing_techniques.html">Evaluating RAG Architectures on Benchmark Tasks</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Benchmarking Without LangSmith</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="run_without_langsmith.html">Running Locally</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/models.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/langchain-ai/langchain-benchmarks" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/langchain-ai/langchain-benchmarks/blob/main/docs/source/notebooks/models.ipynb?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/langchain-ai/langchain-benchmarks/issues/new?title=Issue%20on%20page%20%2Fnotebooks/models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/models.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Model Registry</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">Indexing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#use-the-model">Use the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iteration">Iteration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slicing">Slicing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering">Filtering</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="model-registry">
<h1>Model Registry<a class="headerlink" href="#model-registry" title="Permalink to this heading">#</a></h1>
<p>LangChain Benchmark includes a model registry to make it easier to run benchmarks across different models.</p>
<p>If you see a model that you want to use and itâ€™s missing, please open a PR to add it!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_benchmarks</span> <span class="kn">import</span> <span class="n">model_registry</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_registry</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead>
<tr><th>Name                  </th><th>Type  </th><th>Provider  </th><th>Description                                                                                                                                                                                                                                              </th></tr>
</thead>
<tbody>
<tr><td>gpt-3.5-turbo-1106    </td><td>chat  </td><td>openai    </td><td>The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens.                                                                      </td></tr>
<tr><td>gpt-3.5-turbo         </td><td>chat  </td><td>openai    </td><td>Currently points to gpt-3.5-turbo-0613.                                                                                                                                                                                                                  </td></tr>
<tr><td>gpt-3.5-turbo-16k     </td><td>chat  </td><td>openai    </td><td>Currently points to gpt-3.5-turbo-0613.                                                                                                                                                                                                                  </td></tr>
<tr><td>gpt-3.5-turbo-instruct</td><td>llm   </td><td>openai    </td><td>Similar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions.                                                                                                                                       </td></tr>
<tr><td>gpt-3.5-turbo-0613    </td><td>chat  </td><td>openai    </td><td>Legacy Snapshot of gpt-3.5-turbo from June 13th 2023. Will be deprecated on June 13, 2024.                                                                                                                                                               </td></tr>
<tr><td>gpt-3.5-turbo-16k-0613</td><td>chat  </td><td>openai    </td><td>Legacy Snapshot of gpt-3.5-16k-turbo from June 13th 2023. Will be deprecated on June 13, 2024.                                                                                                                                                           </td></tr>
<tr><td>gpt-3.5-turbo-0301    </td><td>chat  </td><td>openai    </td><td>Legacy Snapshot of gpt-3.5-turbo from March 1st 2023. Will be deprecated on June 13th 2024.                                                                                                                                                              </td></tr>
<tr><td>text-davinci-003      </td><td>llm   </td><td>openai    </td><td>Legacy Can do language tasks with better quality and consistency than the curie, babbage, or ada models. Will be deprecated on Jan 4th 2024.                                                                                                             </td></tr>
<tr><td>text-davinci-002      </td><td>llm   </td><td>openai    </td><td>Legacy Similar capabilities to text-davinci-003 but trained with supervised fine-tuning instead of reinforcement learning. Will be deprecated on Jan 4th 2024.                                                                                           </td></tr>
<tr><td>code-davinci-002      </td><td>llm   </td><td>openai    </td><td>Legacy Optimized for code-completion tasks. Will be deprecated on Jan 4th 2024.                                                                                                                                                                          </td></tr>
<tr><td>gpt-4-1106-preview    </td><td>chat  </td><td>openai    </td><td>GPT-4 TurboNew - The latest GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic.</td></tr>
<tr><td>gpt-4-0613            </td><td>chat  </td><td>openai    </td><td>Snapshot of gpt-4 from June 13th 2023 with improved function calling support.                                                                                                                                                                            </td></tr>
<tr><td>gpt-4-32k-0613        </td><td>chat  </td><td>openai    </td><td>Snapshot of gpt-4-32k from June 13th 2023 with improved function calling support.                                                                                                                                                                        </td></tr>
<tr><td>gpt-4-0314            </td><td>chat  </td><td>openai    </td><td>Snapshot of gpt-4 from March 14th 2023 with function calling support. This model version will be deprecated on June 13th 2024.                                                                                                                           </td></tr>
<tr><td>gpt-4-32k-0314        </td><td>chat  </td><td>openai    </td><td>Snapshot of gpt-4-32k from March 14th 2023 with function calling support. This model version will be deprecated on June 13th 2024.                                                                                                                       </td></tr>
<tr><td>llama-v2-7b-chat-fw   </td><td>chat  </td><td>fireworks </td><td>7b parameter LlamaChat model                                                                                                                                                                                                                             </td></tr>
<tr><td>llama-v2-13b-chat-fw  </td><td>chat  </td><td>fireworks </td><td>13b parameter LlamaChat model                                                                                                                                                                                                                            </td></tr>
<tr><td>llama-v2-70b-chat-fw  </td><td>chat  </td><td>fireworks </td><td>70b parameter LlamaChat model                                                                                                                                                                                                                            </td></tr>
<tr><td>mixtral-8x7b-fw-chat  </td><td>chat  </td><td>fireworks </td><td>8x7b parameter mixture of experts Mistral model, adapted for Chats                                                                                                                                                                                       </td></tr>
<tr><td>mixtral-8x7b-fw-llm   </td><td>llm   </td><td>fireworks </td><td>8x7b parameter mixture of experts Mistral model                                                                                                                                                                                                          </td></tr>
<tr><td>claude-2              </td><td>chat  </td><td>anthropic </td><td>Superior performance on tasks that require complex reasoning                                                                                                                                                                                             </td></tr>
<tr><td>claude-2.1            </td><td>chat  </td><td>anthropic </td><td>Same performance as Claude 2, plus significant reduction in model hallucination rates                                                                                                                                                                    </td></tr>
<tr><td>claude-instant-1.2    </td><td>chat  </td><td>anthropic </td><td>low-latency, high throughput.                                                                                                                                                                                                                            </td></tr>
<tr><td>claude-instant-1      </td><td>chat  </td><td>anthropic </td><td>low-latency, high throughput.                                                                                                                                                                                                                            </td></tr>
</tbody>
</table></div></div>
</div>
<section id="indexing">
<h2>Indexing<a class="headerlink" href="#indexing" title="Permalink to this heading">#</a></h2>
<p>Registry supports indexing by position. This ordering may change as more models get added.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">registered_model</span> <span class="o">=</span> <span class="n">model_registry</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">registered_model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<tbody>
<tr><td>name       </td><td>gpt-3.5-turbo-1106                                                                                                                                                                 </td></tr>
<tr><td>type       </td><td>chat                                                                                                                                                                               </td></tr>
<tr><td>provider   </td><td>openai                                                                                                                                                                             </td></tr>
<tr><td>description</td><td>The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens.</td></tr>
<tr><td>model_path </td><td>langchain.chat_models.openai.ChatOpenAI                                                                                                                                            </td></tr>
<tr><td>url        </td><td><a href="langchain.chat_models.openai.ChatOpenAI" target="_blank" rel="noopener">ModelPage</a>                                                                                     </td></tr>
</tbody>
</table></div></div>
</div>
<p>Can also index by model name</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_registry</span><span class="p">[</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<tbody>
<tr><td>name       </td><td>gpt-3.5-turbo                                                                                 </td></tr>
<tr><td>type       </td><td>chat                                                                                          </td></tr>
<tr><td>provider   </td><td>openai                                                                                        </td></tr>
<tr><td>description</td><td>Currently points to gpt-3.5-turbo-0613.                                                       </td></tr>
<tr><td>model_path </td><td>langchain.chat_models.openai.ChatOpenAI                                                       </td></tr>
<tr><td>url        </td><td><a href="langchain.chat_models.openai.ChatOpenAI" target="_blank" rel="noopener">ModelPage</a></td></tr>
</tbody>
</table></div></div>
</div>
</section>
<section id="use-the-model">
<h2>Use the model<a class="headerlink" href="#use-the-model" title="Permalink to this heading">#</a></h2>
<p>To use the models, make sure that you have credentials set up. Most models take either an API key as part of the initializer or will use any ENV variables that might be present.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model_registry</span><span class="p">[</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;hello! what is your name?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AIMessage(content=&quot;Hello! I am an AI language model developed by OpenAI, and I don&#39;t have a personal name. You can simply refer to me as OpenAI Assistant. How can I assist you today?&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model_registry</span><span class="p">[</span><span class="s2">&quot;claude-2.1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;hello! what is your name?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AIMessage(content=&#39; Hello! My name is Claude.&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="iteration">
<h2>Iteration<a class="headerlink" href="#iteration" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">registered_model</span> <span class="ow">in</span> <span class="n">model_registry</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">registered_model</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">registered_model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;What is your name?&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># chat message</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Failed: </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">e</span><span class="p">)[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>  <span class="c1"># Fails if account does not have access to particular model or due to network limits etc</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-
gpt-3.5-turbo-1106
I am a language model AI created by OpenAI and do not have a personal name. You can call me OpenAI. 
-
gpt-3.5-turbo
I am an AI language model created by OpenAI, so I don&#39;t have a personal name. You can simply refer t
-
gpt-3.5-turbo-16k
I am an AI language model developed by OpenAI, and I do not have a personal name. You can simply ref
-
gpt-3.5-turbo-instruct


I am an AI digital assistant and do not have a name. You can call me OpenAI. What can I assist you
-
gpt-3.5-turbo-0613
I am an AI language model developed by OpenAI and I don&#39;t have a personal name. You can call me Open
-
gpt-3.5-turbo-16k-0613
I am an artificial intelligence created by OpenAI, so I don&#39;t have a personal name. You can refer to
-
gpt-3.5-turbo-0301
As an AI language model, I do not have a personal name. You can call me OpenAI or simply AI.
-
text-davinci-003


My name is Rebecca.
-
text-davinci-002


My name is Sarah.
-
code-davinci-002
Failed: InvalidRequestError(message=&#39;The model `code-davinci-002` does not exist or you do not have access to it.&#39;, param=None, code=&#39;model_not_found&#39;, http_status=404, request_id=None)
-
gpt-4-1106-preview
I am an AI developed by OpenAI, so I don&#39;t have a personal name. However, you can refer to me as Cha
-
gpt-4-0613
I am an artificial intelligence and do not have a personal name. I am often referred to as OpenAI.
-
gpt-4-32k-0613
Failed: InvalidRequestError(message=&#39;The model `gpt-4-32k-0613` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.&#39;, param=None, co
-
gpt-4-0314
I am an AI language model, so I don&#39;t have a personal name. You can call me OpenAI Assistant if you&#39;
-
gpt-4-32k-0314
Failed: InvalidRequestError(message=&#39;The model `gpt-4-32k-0314` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.&#39;, param=None, co
-
llama-v2-7b-chat-fw
Hello! My name is Assistant, and I&#39;m here to help you with any questions or concerns you may have. I
-
llama-v2-13b-chat-fw
Hello! My name is LLaMA, I&#39;m a helpful and respectful assistant developed by Meta AI. I&#39;m here to as
-
llama-v2-70b-chat-fw
Hello! My name is Assistant, and I&#39;m here to help you with any questions or concerns you may have. I
-
mixtral-8x7b-fw-chat
My name is Mistral 7B with 8 Experts MoE model. I am a large language model created by Mistral.ai an
-
mixtral-8x7b-fw-llm


Where are you from?

I was born in Los Angeles, but grew up in Phoenix, Arizona. I moved back to L
-
claude-2
 My name is Claude.
-
claude-2.1
 My name is Claude.
-
claude-instant-1.2
 My name is Claude.
-
claude-instant-1
 My name is Claude.
</pre></div>
</div>
</div>
</div>
</section>
<section id="slicing">
<h2>Slicing<a class="headerlink" href="#slicing" title="Permalink to this heading">#</a></h2>
<p>Slicing notation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_registry</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead>
<tr><th>Name              </th><th>Type  </th><th>Provider  </th><th>Description                                                                                                                                                                        </th></tr>
</thead>
<tbody>
<tr><td>gpt-3.5-turbo-1106</td><td>chat  </td><td>openai    </td><td>The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens.</td></tr>
<tr><td>gpt-3.5-turbo     </td><td>chat  </td><td>openai    </td><td>Currently points to gpt-3.5-turbo-0613.                                                                                                                                            </td></tr>
<tr><td>gpt-3.5-turbo-16k </td><td>chat  </td><td>openai    </td><td>Currently points to gpt-3.5-turbo-0613.                                                                                                                                            </td></tr>
</tbody>
</table></div></div>
</div>
</section>
<section id="filtering">
<h2>Filtering<a class="headerlink" href="#filtering" title="Permalink to this heading">#</a></h2>
<p>Filtering</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_registry</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;fireworks&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead>
<tr><th>Name                </th><th>Type  </th><th>Provider  </th><th>Description                                                       </th></tr>
</thead>
<tbody>
<tr><td>llama-v2-7b-chat-fw </td><td>chat  </td><td>fireworks </td><td>7b parameter LlamaChat model                                      </td></tr>
<tr><td>llama-v2-13b-chat-fw</td><td>chat  </td><td>fireworks </td><td>13b parameter LlamaChat model                                     </td></tr>
<tr><td>llama-v2-70b-chat-fw</td><td>chat  </td><td>fireworks </td><td>70b parameter LlamaChat model                                     </td></tr>
<tr><td>mixtral-8x7b-fw-chat</td><td>chat  </td><td>fireworks </td><td>8x7b parameter mixture of experts Mistral model, adapted for Chats</td></tr>
<tr><td>mixtral-8x7b-fw-llm </td><td>llm   </td><td>fireworks </td><td>8x7b parameter mixture of experts Mistral model                   </td></tr>
</tbody>
</table></div></div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="getting_started.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Getting Started</p>
      </div>
    </a>
    <a class="right-next"
       href="datasets.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Datasets</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">Indexing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#use-the-model">Use the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iteration">Iteration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slicing">Slicing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering">Filtering</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Langchain AI
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023, Langchain AI.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>